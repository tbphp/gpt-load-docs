{
  "nav": {
    "home": "Home",
    "docs": "Docs",
    "sponsor": "Sponsor",
    "github": "GitHub",
    "menu": "Docs Menu",
    "close": "Close Menu"
  },
  "hero": {
    "title": "GPT-Load",
    "subtitle": "High-Performance AI API Transparent Proxy",
    "description": "Enterprise-grade AI API proxy service developed with Go 1.23+, supporting multiple AI providers like OpenAI, Google Gemini, Anthropic Claude. Features intelligent key management, load balancing, high concurrency handling, and comprehensive monitoring.",
    "buttons": {
      "docs": "Documentation",
      "install": "Installation",
      "github": "GitHub"
    },
    "tech": {
      "backend": "Backend Language",
      "database": "Data Storage",
      "cache": "Cache System", 
      "frontend": "Admin Interface"
    },
    "quickStart": {
      "title": "Quick Start",
      "security": {
        "title": "Security Warning",
        "message": "Please replace 'your-secure-key-here' with a strong key! Using default or simple keys poses serious security risks."
      },
      "access": "Access admin panel:"
    }
  },
  "architecture": {
    "title": "System Architecture",
    "subtitle": "High-Performance Transparent Proxy Architecture",
    "description": "GPT-Load adopts a three-tier architecture design to provide high-performance, high-availability AI API proxy services",
    "components": {
      "client": {
        "title": "Client Applications",
        "description": "Web/Mobile apps call through standard OpenAI API format",
        "items": ["HTTP/HTTPS Requests", "Bearer Token Auth", "JSON Format Interaction"]
      },
      "proxy": {
        "title": "GPT-Load Proxy Layer",
        "description": "Core proxy service responsible for request forwarding and management",
        "items": ["Transparent Proxy", "Key Management", "Load Balancing", "Request Logging"]
      },
      "providers": {
        "title": "AI Service Providers",
        "description": "Unified access to multiple AI services",
        "items": ["OpenAI API", "Google Gemini", "Anthropic Claude", "Other Compatible Services"]
      }
    },
    "infrastructure": {
      "title": "Infrastructure",
      "mysql": {
        "title": "MySQL 8.2+",
        "description": "Persistent Storage",
        "details": ["Config Data", "User Info", "Request Logs"]
      },
      "redis": {
        "title": "Redis",
        "description": "Cache & Locks",
        "details": ["Key Cache", "Distributed Locks", "Session Storage"]
      },
      "management": {
        "title": "Management Interface",
        "description": "Web Control Panel",
        "details": ["Visual Config", "Monitor Dashboard", "Log Viewer"]
      }
    }
  },
  "features": {
    "title": "Core Features",
    "subtitle": "Enterprise-Grade Functionality",
    "highPerformance": {
      "title": "High-Performance Architecture",
      "description": "Built with Go 1.23+, zero-copy streaming, coroutine concurrency model, supporting high concurrent processing",
      "technical": "Go Coroutines + HTTP/2 Connection Pooling"
    },
    "transparentProxy": {
      "title": "Transparent Proxy",
      "description": "Fully preserves native API formats, no code changes needed to access multiple AI services",
      "technical": "OpenAI + Gemini + Anthropic Support"
    },
    "keyManagement": {
      "title": "Intelligent Key Management",
      "description": "Group management, dynamic rotation, automatic retry, ensuring high service availability",
      "technical": "Redis Cache + Fault Recovery"
    },
    "loadBalancing": {
      "title": "Load Balancing",
      "description": "Multi-upstream support, weight configuration, health checks, intelligent routing to available nodes",
      "technical": "Weighted Round-Robin + Health Checks"
    },
    "hotReload": {
      "title": "Hot Reload Configuration",
      "description": "Three-tier config system: environment variables, system settings, group configs, supports hot updates",
      "technical": "Environment Variables ‚Üí System Settings ‚Üí Group Settings"
    },
    "clusterSupport": {
      "title": "Cluster Support",
      "description": "Horizontal scaling, distributed deployment, high-availability architecture design",
      "technical": "Docker + Kubernetes Support"
    },
    "security": {
      "title": "Security Mechanisms",
      "description": "Bearer Token authentication, group isolation, request logging, sensitive information masking",
      "technical": "JWT + Access Control + Audit Logs"
    },
    "admin": {
      "title": "Admin Dashboard",
      "description": "Vue 3 modern interface with real-time monitoring, log viewing, and configuration management",
      "technical": "Vue 3 + TypeScript + Naive UI"
    },
    "developerFriendly": {
      "title": "Developer Friendly",
      "description": "Complete RESTful API, detailed documentation, Docker one-click deployment",
      "technical": "OpenAPI + Docker Compose"
    }
  },
  "quickStart": {
    "title": "Quick Start",
    "subtitle": "5-Minute Quick Experience",
    "steps": [
      {
        "title": "Download & Install",
        "description": "One-click deployment with Docker"
      },
      {
        "title": "Configure Keys",
        "description": "Add AI service provider API keys"
      },
      {
        "title": "Start Using",
        "description": "Access AI services through proxy address"
      }
    ],
    "getStarted": "Get Started"
  },
  "cta": {
    "title": "Start Using GPT-Load Now",
    "subtitle": "Deploy in minutes and enjoy high-performance AI API proxy services",
    "buttons": {
      "quickDeploy": "Quick Deploy",
      "viewDocs": "View Docs",
      "github": "GitHub",
      "sponsor": "Sponsor"
    }
  },
  "footer": {
    "description": "High-performance AI gateway providing unified load balancing and key management for multiple large model services.",
    "product": "Product",
    "community": "Community",
    "resources": "Deployment",
    "links": {
      "docs": "Documentation",
      "changelog": "Changelog",
      "sponsor": "Sponsor",
      "github": "GitHub",
      "issues": "Issues",
      "telegram": "Telegram",
      "standalone": "Standalone",
      "cluster": "Cluster"
    },
    "copyright": "All rights reserved",
    "license": "MIT License",
    "openSource": "open source"
  },
  "dataFlow": "Data Flow Architecture",
  "infrastructure": "Infrastructure Components",
  "deploymentOptions": {
    "title": "Flexible Deployment Options",
    "standalone": {
      "title": "Standalone Deployment",
      "features": [
        "Docker Compose one-click startup",
        "Includes complete MySQL + Redis",
        "Suitable for development and small production"
      ]
    },
    "cluster": {
      "title": "Cluster Deployment",
      "features": [
        "Master/Slave architecture",
        "Horizontal scaling support",
        "High availability guarantee"
      ]
    }
  },
  "systemRequirements": "System Requirements",
  "runtime": "Runtime Environment",
  "storage": "Data Storage",
  "cache": "Cache Service",
  "containerRuntime": "Container Runtime",
  "productionReady": {
    "title": "Production-Ready Enterprise Architecture",
    "description": "From standalone deployment to distributed clusters, from development to production environments, GPT-Load provides complete solutions",
    "runtime": "Runtime Environment",
    "persistence": "Data Persistence",
    "cacheAndLock": "Cache & Locks",
    "adminUI": "Admin Interface"
  },
  "performanceComponent": {
    "title": "Technical Features",
    "subtitle": "High-performance architecture design based on Go 1.23+, providing reliable proxy services for enterprise applications",
    "metrics": {
      "defaultConcurrency": {
        "label": "Default Concurrency",
        "description": "MAX_CONCURRENT_REQUESTS default value"
      },
      "goVersion": {
        "label": "Go Version Requirement",
        "description": "Minimum version requirement"
      },
      "connectionPool": {
        "label": "Connection Pool Config",
        "description": "Max idle connections/per-host connections"
      },
      "requestTimeout": {
        "label": "Request Timeout",
        "description": "Default request timeout"
      }
    },
    "comparison": {
      "title": "Performance Comparison",
      "subtitle": "Comparing direct API calls vs using GPT-Load proxy performance differences",
      "headers": {
        "metric": "Performance Metric",
        "directApi": "Direct API Call",
        "withGptLoad": "Using GPT-Load",
        "improvement": "Performance Improvement"
      },
      "items": {
        "configManagement": {
          "metric": "Config Management",
          "without": "Static Config Files",
          "with": "Dynamic Hot Reload",
          "improvement": "No Restart Required"
        },
        "keyManagement": {
          "metric": "Key Management",
          "without": "Manual Rotation",
          "with": "Auto Fault Recovery",
          "improvement": "Smart Blacklist"
        },
        "clusterDeployment": {
          "metric": "Cluster Deployment",
          "without": "Complex Election Mechanism",
          "with": "IS_SLAVE Flag",
          "improvement": "Simple Configuration"
        },
        "monitoring": {
          "metric": "Monitoring Capability",
          "without": "Basic Logging",
          "with": "Web Admin Interface",
          "improvement": "Real-time Statistics"
        }
      }
    },
    "monitoring": {
      "title": "Real-time Monitoring Features",
      "features": {
        "detailedStats": {
          "title": "Detailed Statistics",
          "description": "Comprehensive monitoring of request count, response time, error rate, etc."
        },
        "healthCheck": {
          "title": "Health Check",
          "description": "Real-time service status monitoring with timely anomaly detection and handling"
        },
        "performanceAnalysis": {
          "title": "Performance Analysis",
          "description": "In-depth analysis of performance bottlenecks to optimize system configuration"
        }
      },
      "dashboard": {
        "title": "Monitoring Dashboard",
        "metrics": {
          "totalRequests": "üü¢ Total Requests:",
          "avgResponse": "‚ö° Avg Response:",
          "activeKeys": "üîë Active Keys:",
          "errorRate": "‚ùå Error Rate:"
        }
      }
    }
  },
  "quickStartComponent": {
    "title": "Quick Start",
    "subtitle": "Start GPT-Load in 3 Steps",
    "description": "Quick deployment via Docker Compose, including complete database and cache services",
    "steps": {
      "clone": {
        "title": "1. Clone Project",
        "description": "Download complete project code from GitHub"
      },
      "configure": {
        "title": "2. Configure Environment",
        "description": "Copy and edit environment configuration file"
      },
      "start": {
        "title": "3. Start Services",
        "description": "Use Docker Compose for one-click startup"
      }
    },
    "requirements": {
      "title": "System Requirements",
      "runtime": "Runtime Environment",
      "storage": "Data Storage",
      "cache": "Cache Service",
      "containerRuntime": "Container Runtime",
      "viewDocs": "View Detailed Deployment Documentation"
    },
    "codeComments": {
      "copyEnv": "Copy environment configuration file",
      "editConfig": "Edit configuration (optional)",
      "mainConfig": "Main configuration items:",
      "startServices": "Start services (including MySQL and Redis)",
      "accessAdmin": "Access admin interface"
    }
  },
  "docs": {
    "quickStart": "Quick Start",
    "introduction": "Introduction",
    "deployment": "Deployment",
    "standalone": "Standalone",
    "source": "Source Code",
    "cluster": "Cluster",
    "clawCloud": "Claw Cloud",
    "configuration": "Configuration",
    "environment": "Environment",
    "project": "Project",
    "management": "Management",
    "cloudflareAigateway": "Cloudflare AI Gateway",
    "architectureDesign": "Architecture & Design",
    "performance": "Performance",
    "routingStrategy": "Routing Strategy",
    "keyManagement": "Key Management", 
    "channels": "Channels",
    "geminiOpenai": "Gemini Official OpenAI Compatible",
    "integrations": "Integrations",
    "rooCode": "Roo Code",
    "claudeCodeRouter": "Claude Code Router",
    "newApi": "New API",
    "cherryStudio": "Cherry Studio",
    "sponsor": "Sponsor",
    "contributors": "Contributors"
  },
  "geminiOpenai": {
    "title": "Gemini Official OpenAI Compatible Format",
    "subtitle": "GPT-Load now supports Google Gemini's official OpenAI compatible format, allowing you to access the powerful capabilities of Gemini models using standard OpenAI SDK and tools.",
    "notice": "Note: This is not format conversion, but transparent proxying of Gemini's official OpenAI compatible format. For details, please refer to the official documentation:",
    "configuration": {
      "title": "Configuration in GPT-Load",
      "steps": [
        {
          "title": "Step 1: Create Gemini Group",
          "items": [
            "‚Ä¢ <strong>Group Name</strong>: gemini (recommended name)",
            "‚Ä¢ <strong>Channel Type</strong>: Select &ldquo;gemini&rdquo; type",
            "‚Ä¢ <strong>Upstream Address</strong>: https://generativelanguage.googleapis.com",
            "‚Ä¢ <strong>API Key</strong>: Add your Gemini API Key"
          ]
        },
        {
          "title": "Step 2: Get Proxy Endpoint",
          "items": []
        }
      ],
      "groupConfig": {
        "title": "Group Configuration"
      },
      "importantNotes": {
        "title": "Important Notes",
        "items": [
          "‚Ä¢ Use official Google generativelanguage.googleapis.com endpoint",
          "‚Ä¢ Ensure API key is valid and has sufficient quota",
          "‚Ä¢ Group will automatically support OpenAI compatible format after creation",
          "‚Ä¢ Supports load balancing and failover"
        ]
      },
      "proxyEndpoint": {
        "format": "Proxy Endpoint Format:",
        "description": "GPT-Load will generate dedicated OpenAI compatible endpoints for Gemini groups",
        "fullPath": "Complete Call Path",
        "endpoint": "http://localhost:3001/proxy/gemini/v1beta/openai/chat/completions"
      }
    },
    "examples": {
      "title": "Client Call Examples",
      "cherryStudio": {
        "title": "Cherry Studio Configuration",
        "recommended": "Recommended:",
        "description": "Cherry Studio is an excellent AI client that perfectly supports Gemini OpenAI compatible format",
        "stepsTitle": "Configuration Steps",
        "steps": [
          "Open Cherry Studio",
          "Create new channel, select OpenAI as provider type",
          "Set base URL to proxy endpoint",
          "Enter proxy key",
          "Start using Gemini models"
        ],
        "paramsTitle": "Configuration Parameters",
        "params": [
          {
            "label": "Provider Type:",
            "value": "OpenAI"
          },
          {
            "label": "Base URL:",
            "value": "http://localhost:3001/proxy/gemini/v1beta/openai/",
            "note": "(Must end with /)"
          },
          {
            "label": "API Key:",
            "value": "your-proxy-key"
          }
        ]
      },
      "curl": {
        "title": "cURL Direct Call",
        "code": "curl -X POST \"http://localhost:3001/proxy/gemini/v1beta/openai/chat/completions\" \\\\\n  -H \"Authorization: Bearer your-proxy-key\" \\\\\n  -H \"Content-Type: application/json\" \\\\\n  -d '{\n    \"model\": \"gemini-2.5-flash\",\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"hi\"\n      }\n    ]\n  }'"
      }
    },
    "notes": {
      "title": "Notes",
      "items": [
        "‚Ä¢ Ensure GPT-Load version is latest to support Gemini OpenAI compatible format",
        "‚Ä¢ Cherry Studio base URL must end with slash (/), otherwise calls may fail",
        "‚Ä¢ Gemini API Key needs sufficient quota and correct permissions"
      ]
    }
  },
  "standalone": {
    "title": "Standalone Deployment",
    "subtitle": "Standalone deployment is the simplest deployment method for GPT-Load, suitable for individual users and small teams to get started quickly. Supports from lightweight quick start to optional deployment with full functionality.",
    "quickStart": {
      "title": "Quick Start",
      "lightweight": {
        "title": "Lightweight Deployment",
        "description": "Uses SQLite database and memory storage, best for personal use and quick experience"
      }
    },
    "requirements": {
      "title": "System Requirements",
      "items": [
        "Docker 20.10+ and Docker Compose",
        "Linux/macOS/Windows operating systems",
        "At least 128MB memory and 1GB disk space"
      ]
    },
    "installation": {
      "title": "Installation Steps",
      "step1": {
        "title": "Create Working Directory",
        "comment": "# Create directory and enter"
      },
      "step2": {
        "title": "Download and Configure Security Parameters",
        "dockerComment": "# Download Docker Compose configuration",
        "envComment": "# Download environment variable configuration",
        "securityConfig": {
          "title": "Must Execute: Modify Management Key",
          "editFile": "Immediately edit",
          "changeFrom": "file, change:",
          "changeTo": "to a secure key:",
          "reminder": {
            "title": "Reminder:",
            "message": "Please generate your own random key, do not use the example key above!"
          }
        }
      },
      "step3": {
        "title": "Start Services",
        "comment": "# Start GPT-Load service"
      },
      "step4": {
        "title": "Verify Deployment",
        "accessAdmin": "Access admin interface:",
        "useAuthKey": "Login with your custom management key",
        "fileSet": "That is, the",
        "login": "value set in the",
        "value": "file",
        "securityTip": {
          "title": "Security Tip:",
          "message": "Please keep your management key safe and do not store it in plain text in logs, documents, or code."
        }
      }
    },
    "security": {
      "warning": {
        "title": "Critical Security Warning",
        "message": "You must change the default management key before deployment, otherwise there are serious security risks!"
      },
      "requirements": {
        "title": "Security Key Requirements:",
        "items": [
          "At least 20 characters",
          "Include uppercase letters, lowercase letters, numbers, and special symbols",
          "Avoid using dictionary words or personal information",
          "Recommended format: sk-prod-[32-character random string]"
        ]
      },
      "risk": "‚ö†Ô∏è Using weak keys may lead to malicious system access, causing data leaks or service abuse!"
    },
    "commonCommands": {
      "title": "Common Commands",
      "items": [
        {
          "title": "Check Status",
          "code": "docker compose ps"
        },
        {
          "title": "View Logs",
          "code": "docker compose logs -f"
        },
        {
          "title": "Restart Service",
          "code": "docker compose down && docker compose up -d"
        },
        {
          "title": "Update Version",
          "code": "docker compose pull && docker compose down && docker compose up -d"
        }
      ]
    },
    "optional": {
      "title": "Optional Deployment",
      "performance": {
        "title": "Enhanced Performance",
        "description": "Configure MySQL/PostgreSQL database and Redis cache to improve system performance and reliability"
      },
      "database": {
        "title": "Database Configuration",
        "configs": [
          {
            "name": "MySQL Configuration",
            "steps": [
              "1. Edit <code class=\"bg-gray-100 px-1 rounded\">docker-compose.yml</code>, uncomment MySQL service:<div class=\"bg-gray-900 text-gray-100 p-4 rounded-lg text-sm\"><code>&nbsp;&nbsp;depends_on:<br />&nbsp;&nbsp;&nbsp;&nbsp;mysql:<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;condition: service_healthy<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;restart: true<br /><br />mysql:<br />&nbsp;&nbsp;image: mysql:8.2<br />&nbsp;&nbsp;container_name: gpt-load-mysql<br />&nbsp;&nbsp;restart: always<br />&nbsp;&nbsp;environment:<br />&nbsp;&nbsp;&nbsp;&nbsp;MYSQL_ROOT_PASSWORD: 123456<br />&nbsp;&nbsp;&nbsp;&nbsp;MYSQL_DATABASE: gpt-load<br />&nbsp;&nbsp;volumes:<br />&nbsp;&nbsp;&nbsp;&nbsp;- ./data/mysql:/var/lib/mysql<br />&nbsp;&nbsp;healthcheck:<br />&nbsp;&nbsp;&nbsp;&nbsp;test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"]<br />&nbsp;&nbsp;&nbsp;&nbsp;interval: 5s<br />&nbsp;&nbsp;&nbsp;&nbsp;timeout: 5s<br />&nbsp;&nbsp;&nbsp;&nbsp;retries: 10</code></div>",
              "2. Configure database connection in <code class=\"bg-gray-100 px-1 rounded\">.env</code> file:<div class=\"bg-gray-900 text-gray-100 p-4 rounded-lg text-sm\"><code>DATABASE_DSN=root:123456@tcp(mysql:3306)/gpt-load?charset=utf8mb4&parseTime=True&loc=Local</code></div>"
            ]
          },
          {
            "name": "PostgreSQL Configuration",
            "steps": [
              "1. Edit <code class=\"bg-gray-100 px-1 rounded\">docker-compose.yml</code>, uncomment PostgreSQL service:<div class=\"bg-gray-900 text-gray-100 p-4 rounded-lg text-sm\"><code>&nbsp;&nbsp;depends_on:<br />&nbsp;&nbsp;&nbsp;&nbsp;postgres:<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;condition: service_healthy<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;restart: true<br /><br />postgres:<br />&nbsp;&nbsp;image: \"postgres:16\"<br />&nbsp;&nbsp;container_name: gpt-load-postgres<br />&nbsp;&nbsp;environment:<br />&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_USER: postgres<br />&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_PASSWORD: 123456<br />&nbsp;&nbsp;&nbsp;&nbsp;POSTGRES_DB: gpt-load<br />&nbsp;&nbsp;volumes:<br />&nbsp;&nbsp;&nbsp;&nbsp;- ./data/postgres:/var/lib/postgresql/data<br />&nbsp;&nbsp;healthcheck:<br />&nbsp;&nbsp;&nbsp;&nbsp;test: [\"CMD-SHELL\", \"pg_isready -U postgres -d \"]<br />&nbsp;&nbsp;&nbsp;&nbsp;interval: 5s<br />&nbsp;&nbsp;&nbsp;&nbsp;timeout: 5s<br />&nbsp;&nbsp;&nbsp;&nbsp;retries: 10</code></div>",
              "2. Configure database connection in <code class=\"bg-gray-100 px-1 rounded\">.env</code> file:<div class=\"bg-gray-900 text-gray-100 p-4 rounded-lg text-sm\"><code>DATABASE_DSN=postgres://postgres:123456@postgres:5432/gpt-load?sslmode=disable</code></div>"
            ]
          }
        ]
      },
      "redis": {
        "title": "Redis Configuration",
        "step1": {
          "description": "1. Edit",
          "action": ", uncomment Redis service:",
          "code": "&nbsp;&nbsp;depends_on:<br />&nbsp;&nbsp;&nbsp;&nbsp;redis:<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;condition: service_healthy<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;restart: true<br /><br />redis:<br />&nbsp;&nbsp;image: redis:latest<br />&nbsp;&nbsp;container_name: gpt-load-redis<br />&nbsp;&nbsp;restart: always<br />&nbsp;&nbsp;healthcheck:<br />&nbsp;&nbsp;&nbsp;&nbsp;test: [\"CMD\", \"redis-cli\", \"ping\"]<br />&nbsp;&nbsp;&nbsp;&nbsp;interval: 5s<br />&nbsp;&nbsp;&nbsp;&nbsp;timeout: 3s<br />&nbsp;&nbsp;&nbsp;&nbsp;retries: 3"
        },
        "step2": {
          "description": "2. Configure Redis connection in",
          "action": "file:"
        }
      },
      "restart": {
        "title": "Restart Services",
        "description": "After configuration is complete, restart all services:",
        "stopComment": "# Stop services",
        "startComment": "# Restart services"
      }
    },
    "troubleshooting": {
      "title": "Troubleshooting",
      "commonIssues": {
        "title": "Common Issues"
      },
      "items": [
        {
          "title": "Cannot login to admin interface",
          "description": "Please check if you are using the correct management key:",
          "solution": "<ul class=\"text-gray-600 text-sm space-y-1 ml-4\"><li>‚Ä¢ Confirm that AUTH_KEY in <code class=\"bg-gray-100 px-1 rounded\">.env</code> file has been modified</li><li>‚Ä¢ The new key takes effect after restarting the service: <code class=\"bg-gray-100 px-1 rounded\">docker compose restart</code></li><li>‚Ä¢ Keys are case-sensitive, please ensure correct input</li></ul>"
        },
        {
          "title": "Port conflict",
          "description": "If port 3001 is occupied, you can modify it in <code class=\"bg-gray-100 px-1 rounded\">.env</code> file:",
          "solution": "<div class=\"bg-gray-100 p-2 rounded text-sm\"><code>PORT=3002</code></div>"
        },
        {
          "title": "Database connection failed",
          "description": "Check if database service is running normally:",
          "solution": "<div class=\"bg-gray-100 p-2 rounded text-sm\"><code>docker compose logs mysql</code></div>"
        },
        {
          "title": "Insufficient memory",
          "description": "Ensure the system has sufficient memory resources. After enabling database services, at least 1GB of available memory is recommended",
          "solution": ""
        }
      ]
    },
    "nextSteps": {
      "title": "Next Steps",
      "description": "After deployment is complete, you can:",
      "items": [
        "Configure proxy keys and manage AI service groups",
        "Add and manage AI service provider API keys",
        "Adjust system configuration and performance parameters",
        "Start using API proxy services"
      ],
      "buttons": {
        "configuration": "View Configuration Guide",
        "management": "Management Configuration"
      }
    }
  },
  "clawCloud": {
    "title": "Claw Cloud Deployment",
    "subtitle": "Deploy GPT-Load to Claw Cloud for free. No server required, one-click deployment for quick experience.",
    "warning": {
      "title": "‚ö†Ô∏è Important Notice: Please Back Up Your Data!",
      "description": "Claw Cloud is an experimental free service with no stability guarantee. The following risks exist:",
      "risks": [
        "Service may become unstable or temporarily unavailable",
        "Data may be lost due to service failures", 
        "Free service has no SLA guarantee",
        "Instances may be restarted or reassigned"
      ],
      "recommendation": {
        "title": "üîÑ Strong Recommendations:",
        "items": [
          "Regularly export and backup your configuration data",
          "Save all important API keys and configuration information",
          "Consider stable paid cloud services for production environments",
          "Use Claw Cloud only for testing and learning purposes"
        ]
      }
    },
    "overview": {
      "title": "Service Overview",
      "service": {
        "title": "Claw Cloud Free Deployment",
        "description": "Lightweight cloud deployment solution using SQLite database and memory storage, with completely free $5 monthly quota"
      },
      "features": {
        "freeQuota": {
          "title": "Free Quota",
          "description": "$5 free usage quota per month"
        },
        "globalDeploy": {
          "title": "Global Deployment",
          "description": "Support multiple region deployment to optimize access speed"
        },
        "simpleAuth": {
          "title": "Simple Authentication",
          "description": "Only requires GitHub account to get started"
        }
      }
    },
    "prerequisites": {
      "title": "Prerequisites",
      "accountRequirement": {
        "title": "Account Requirements",
        "description": "Requires a GitHub account with more than 6 months of history to use Claw Cloud service"
      },
      "serviceFeatures": {
        "title": "Service Features",
        "freeQuota": {
          "title": "Free Quota",
          "items": [
            "‚Ä¢ $5 free usage quota per month",
            "‚Ä¢ Suitable for personal users and small-scale testing",
            "‚Ä¢ No credit card verification required",
            "‚Ä¢ Option to pay for continued use after exceeding quota"
          ]
        },
        "techSpecs": {
          "title": "Technical Specifications",
          "items": [
            "‚Ä¢ Uses SQLite database",
            "‚Ä¢ Memory storage (no Redis)",
            "‚Ä¢ Automatic backup and recovery",
            "‚Ä¢ Built-in monitoring and logging"
          ]
        }
      }
    },
    "deploymentSteps": {
      "title": "Deployment Steps",
      "step1": {
        "title": "Register and Login",
        "githubLogin": {
          "title": "Login to Claw Cloud with GitHub",
          "description": "Visit the Claw Cloud website and click 'Get started for free', then login with your GitHub account."
        },
        "regionSelection": {
          "title": "Select Deployment Region",
          "description": "After login, select an appropriate deployment region in the top-left corner:",
          "recommended": "Recommended regions:",
          "regions": [
            "‚Ä¢ Singapore - Singapore",
            "‚Ä¢ Japan - Japan"
          ]
        },
        "image": {
          "alt": "Claw Cloud region selection interface",
          "caption": "Claw Cloud region selection interface"
        }
      },
      "step2": {
        "title": "Create Application",
        "launchApp": {
          "title": "Launch Application Creation",
          "description": "Click \"App Launchpad\" in the center, then click \"Create App\" in the top-right corner to start creating the application"
        },
        "image": {
          "alt": "Claw Cloud create application interface",
          "caption": "App Launchpad - Create Application"
        }
      },
      "step3": {
        "title": "Configure Application",
        "form": {
          "title": "Fill Application Configuration Form",
          "basic": {
            "title": "Basic (Basic Information)",
            "appName": {
              "label": "Application Name",
              "value": "gpt-load"
            },
            "image": {
              "label": "Image",
              "value": "Select Public"
            },
            "imageName": {
              "label": "Image Name",
              "value": "ghcr.io/tbphp/gpt-load:latest"
            }
          },
          "usage": {
            "title": "Usage (Resource Configuration)",
            "usage": {
              "label": "Usage",
              "value": "Fixed"
            },
            "replicas": {
              "label": "Replicas",
              "value": "1"
            },
            "cpu": {
              "label": "CPU",
              "value": "1 (adjustable as needed)"
            },
            "memory": {
              "label": "Memory",
              "value": "512M (adjustable as needed)"
            }
          },
          "resourceTip": {
            "title": "Resource Configuration Recommendations",
            "description": "Based on the $5 quota calculation, recommended configuration is CPU: 1, Memory: 512M. For personal use with low network traffic, you can reduce configuration to save costs."
          }
        },
        "network": {
          "title": "Network (Network Configuration)",
          "containerPort": {
            "label": "Container Port",
            "value": "3001"
          },
          "publicAccess": {
            "label": "Public Access",
            "value": "‚úÖ Enable"
          }
        },
        "environment": {
          "title": "Environment Variables (Environment Variables)",
          "description": "Click \"Environment Variables\" to add the following configuration:",
          "authKey": {
            "label": "AUTH_KEY",
            "value": "sk-your-custom-key"
          },
          "warning": "‚ö†Ô∏è Please replace sk-your-custom-key with your own password, do not use default values or share publicly"
        },
        "storage": {
          "title": "Local Storage (Storage Configuration)",
          "localStorage": {
            "label": "Local Storage",
            "value": "Click \"Add\" to add storage"
          },
          "capacity": {
            "label": "Capacity",
            "value": "1G"
          },
          "mountPath": {
            "label": "Mount Path",
            "value": "/app/data"
          },
          "note": "After configuration, click \"Confirm\" to save storage configuration"
        },
        "image": {
          "alt": "Claw Cloud application configuration interface",
          "caption": "Application configuration form"
        }
      },
      "step4": {
        "title": "Deploy Application",
        "startDeploy": {
          "title": "Start Deployment",
          "description": "After configuration is complete, click the \"Deploy Application\" button in the top-right corner to start deploying the application"
        },
        "completed": {
          "title": "Deployment Complete",
          "description": "The entire creation process is very simple and convenient! After deployment is complete, wait for the public address to take effect, which may take a few minutes."
        },
        "waitService": {
          "title": "Wait for Service to Start",
          "description": "Patiently wait for the \"Public Address\" status to turn green \"Available\", then you can access your GPT-Load service"
        }
      }
    },
    "accessUsage": {
      "title": "Access and Usage",
      "firstAccess": {
        "title": "First Access",
        "getAddress": {
          "title": "Get Access Address",
          "description": "After deployment is complete, you can see your application's public address in the Claw Cloud console",
          "example": {
            "label": "Access address similar to",
            "value": "https://ax***fta.region.clawcloudrun.com"
          }
        },
        "login": {
          "title": "Login to Management Interface",
          "description": "Visit your application address and use the configured AUTH_KEY to login to the management interface",
          "securityTip": {
            "title": "Security Tip",
            "description": "Please ensure your AUTH_KEY is secure and do not share it in public places or documents"
          }
        }
      },
      "apiUsage": {
        "title": "API Usage",
        "proxyAddress": {
          "title": "API Proxy Address",
          "label": "API proxy endpoint:",
          "value": "https://ax***fta.region.clawcloudrun.com/proxy/{group_name}"
        },
        "example": {
          "title": "Usage Example",
          "code": "curl -X POST https://ax***fta.region.clawcloudrun.com/proxy/openai/v1/chat/completions \\\n  -H \"Authorization: Bearer your-auth-key\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model\": \"gpt-4o-mini\", \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}'"
        }
      }
    },
    "updateMaintenance": {
      "title": "Updates and Maintenance",
      "versionUpdate": {
        "title": "Version Updates",
        "steps": {
          "title": "Update Steps",
          "items": [
            "Enter App Launchpad and select your created application",
            "Click the \"Update\" button in the top-right corner",
            "On the update page, no need to modify any configuration, directly click the \"Update\" button",
            "Wait for update and restart to complete"
          ]
        },
        "autoUpdate": {
          "title": "Automatic Updates",
          "description": "The update process will automatically pull the latest version of the image, no manual configuration required"
        }
      },
      "monitoring": {
        "title": "Monitoring and Logs",
        "appMonitoring": {
          "title": "Application Monitoring",
          "items": [
            "‚Ä¢ View application status in Claw Cloud console",
            "‚Ä¢ Monitor resource usage and costs",
            "‚Ä¢ View application runtime logs",
            "‚Ä¢ Set alerts and notifications"
          ]
        },
        "costControl": {
          "title": "Cost Control",
          "items": [
            "‚Ä¢ Regularly check monthly usage and costs",
            "‚Ä¢ Adjust resource configuration based on actual usage",
            "‚Ä¢ Set budget and cost alerts",
            "‚Ä¢ Consider pausing service during low-traffic periods"
          ]
        }
      }
    },
    "troubleshooting": {
      "title": "Troubleshooting",
      "commonIssues": {
        "title": "Common Issues",
        "appNotStart": {
          "title": "Application Failed to Start",
          "cause": "Possible causes: Image pull failure, configuration errors, or insufficient resources",
          "solution": "Solution: Check application logs, confirm image address and configuration are correct"
        },
        "accessFailed": {
          "title": "Cannot Access Public Address",
          "cause": "Possible causes: DNS propagation delay or network issues",
          "solution": "Solution: Wait a few minutes and retry, check network connection"
        },
        "authFailed": {
          "title": "Authentication Failed",
          "cause": "Possible causes: AUTH_KEY configuration error or not set",
          "solution": "Solution: Check environment variable configuration, ensure AUTH_KEY is correct"
        }
      }
    },
    "nextSteps": {
      "title": "Next Steps",
      "description": "After Claw Cloud deployment is complete, you can:",
      "tasks": [
        "Configure AI services through the Web management interface",
        "Add API keys to start using proxy services",
        "Monitor usage and costs",
        "Upgrade to higher configurations as needed"
      ],
      "buttons": {
        "configuration": "Configuration Guide",
        "management": "Management Configuration"
      }
    }
  },
  "imageViewer": {
    "closeButton": "Close (Esc)",
    "instructions": "Press Esc or click background to close",
    "clickToEnlarge": "Click image to enlarge"
  },
  "docsQuickStart": {
    "title": "Quick Start",
    "subtitle": "Get GPT-Load up and running quickly with these steps.",
    "quickLaunch": {
      "title": "Quick Launch",
      "lightweightDeployment": {
        "title": "Lightweight Deployment",
        "description": "Uses SQLite database and memory storage, perfect for personal use and quick testing"
      }
    },
    "requirements": {
      "title": "System Requirements",
      "docker": "Docker 20.10+ and Docker Compose",
      "os": "Linux/macOS/Windows operating systems",
      "resources": "At least 128MB memory and 1GB disk space"
    },
    "installation": {
      "title": "Installation Steps"
    },
    "security": {
      "title": "Important Security Notice",
      "warning": "You must change the default management key before deployment!",
      "requirements": {
        "complex": "Use at least 20 characters for complex keys",
        "characters": "Include uppercase, lowercase, numbers and special characters",
        "avoid": "Never use",
        "simpleKeys": "or other default/simple keys",
        "productionRisk": "Using weak keys in production environments poses serious security risks"
      },
      "recommendedFormat": "Recommended key format",
      "randomString": "random string",
      "characters": "characters"
    },
    "steps": {
      "createDirectory": {
        "title": "Create Working Directory",
        "comment": "Create directory and enter"
      },
      "downloadConfig": {
        "title": "Download Configuration Files",
        "dockerComment": "Download Docker Compose configuration",
        "envComment": "Download environment variable configuration",
        "securityConfig": {
          "title": "Modify Security Configuration Immediately",
          "editFile": "Edit",
          "changeFrom": "file, change the following:",
          "changeTo": "to a strong key:"
        }
      },
      "startServices": {
        "title": "Start Services",
        "comment": "Start GPT-Load service"
      },
      "verify": {
        "title": "Verify Deployment",
        "accessAdmin": "Access admin interface",
        "useAuthKey": "Use the",
        "fileSet": "set in the",
        "login": "file to login to the admin interface"
      }
    },
    "commands": {
      "title": "Common Commands",
      "checkStatus": "Check Status",
      "viewLogs": "View Logs",
      "restart": "Restart Service",
      "update": "Update Version"
    },
    "nextSteps": {
      "description": "Want to learn more deployment options, such as using MySQL/PostgreSQL or cluster deployment? Check out the complete",
      "deploymentGuide": "Deployment Guide",
      "period": "."
    }
  },
  "architectureDesign": {
    "title": "System Architecture",
    "subtitle": "In-depth understanding of GPT-Load's technical architecture and design philosophy",
    "overview": {
      "title": "Architecture Overview",
      "highlightTitle": "High-Performance Transparent Proxy Architecture",
      "highlightDescription": "High-performance OpenAI API proxy service built on Go language, supporting multi-key rotation, load balancing, and intelligent failover"
    },
    "components": {
      "apiGateway": {
        "title": "API Gateway",
        "description": "Unified API entry point and routing"
      },
      "loadBalancer": {
        "title": "Load Balancer",
        "description": "Intelligent key rotation and distribution"
      },
      "dataStorage": {
        "title": "Data Storage",
        "description": "MySQL + Redis dual storage"
      },
      "securityMonitor": {
        "title": "Security Monitor",
        "description": "Rate limiting, authentication and monitoring"
      }
    },
    "systemComponents": {
      "title": "System Components",
      "coreService": {
        "title": "Core Service Layer",
        "apiProxy": {
          "title": "API Proxy Service",
          "features": ["HTTP/HTTPS transparent proxy", "Request routing and forwarding", "Streaming response processing", "Error handling and retry"]
        },
        "loadBalancer": {
          "title": "Load Balancer",
          "features": ["Round Robin algorithm", "Weight allocation strategy", "Health check mechanism", "Automatic failover"]
        }
      },
      "managementLayer": {
        "title": "Management Service Layer",
        "webInterface": {
          "title": "Web Management Interface",
          "features": ["Vue 3 + TypeScript", "Naive UI component library", "Real-time monitoring dashboard", "Configuration management interface"]
        },
        "restApi": {
          "title": "REST API",
          "features": ["Key management interface", "Statistics data interface", "System configuration interface", "Monitoring metrics interface"]
        }
      },
      "dataLayer": {
        "title": "Data Storage Layer",
        "mysql": {
          "title": "MySQL Database",
          "features": ["Key and configuration persistence", "User authentication data", "Historical statistics records", "System log storage"]
        },
        "redis": {
          "title": "Redis Cache",
          "features": ["Key status cache", "Rate limiting counters", "Distributed lock mechanism", "Session state management"]
        }
      }
    },
    "dataFlow": {
      "title": "Data Flow",
      "steps": [
        {
          "title": "Client Request",
          "description": "API gateway receives OpenAI-compatible requests"
        },
        {
          "title": "Key Selection",
          "description": "Load balancer selects available API keys"
        },
        {
          "title": "Request Forwarding",
          "description": "Proxy service forwards requests to OpenAI API"
        },
        {
          "title": "Response Processing",
          "description": "Streaming response processing and return to client"
        },
        {
          "title": "Data Recording",
          "description": "Statistics and logs recorded to database"
        }
      ]
    },
    "deploymentArchitectures": {
      "title": "Deployment Architectures",
      "standalone": {
        "title": "Standalone Deployment",
        "scenarios": {
          "title": "Applicable Scenarios",
          "items": ["Small to medium-scale applications", "Development and testing environments", "Personal project usage"]
        }
      },
      "cluster": {
        "title": "Cluster Deployment",
        "scenarios": {
          "title": "Applicable Scenarios",
          "items": ["Large-scale production environments", "High availability requirements", "Enterprise-grade applications"]
        }
      }
    },
    "techStack": {
      "title": "Technology Stack",
      "backend": {
        "title": "Backend Technologies",
        "items": ["Go 1.23+", "Gin Web Framework", "GORM ORM", "Go-Redis"]
      },
      "frontend": {
        "title": "Frontend Technologies",
        "items": ["Vue 3", "TypeScript", "Naive UI", "Vite"]
      },
      "infrastructure": {
        "title": "Infrastructure",
        "items": ["MySQL 8.2+", "Redis", "Docker", "Nginx"]
      }
    },
    "designPrinciples": {
      "title": "Design Principles",
      "highPerformance": {
        "title": "High Performance",
        "description": "Go language-based high-concurrency processing capability, supporting thousands of QPS request processing"
      },
      "highAvailability": {
        "title": "High Availability",
        "description": "Automatic failover, health checks, and distributed deployment ensure service availability"
      },
      "scalability": {
        "title": "Scalability",
        "description": "Modular design and microservice architecture support horizontal scaling and feature expansion"
      },
      "transparentProxy": {
        "title": "Transparent Proxy",
        "description": "Fully compatible with OpenAI API, no need to modify existing code for integration"
      }
    }
  },
  "seo": {
    "pages": {
      "home": {
        "title": "GPT-Load - High-Performance AI API Transparent Proxy",
        "description": "Enterprise-grade AI API proxy service that fully preserves native API formats from various AI providers. Features key rotation, multi-group management, load balancing.",
        "keywords": "GPT, OpenAI, API, transparent proxy, load balancing, key rotation, Go, high performance, AI proxy, Gemini, Claude"
      },
      "docs": {
        "quickStart": {
          "title": "Quick Start - GPT-Load Deployment Guide",
          "description": "Deploy GPT-Load in 5 minutes with Docker one-click startup, including complete database and cache services.",
          "keywords": "GPT-Load deployment, Docker deployment, quick start, AI proxy installation"
        }
      },
      "introduction": {
        "title": "Project Introduction - GPT-Load Architecture & Tech Stack",
        "description": "Deep dive into GPT-Load's core concepts, technical architecture, supported AI services, and enterprise-grade features.",
        "keywords": "GPT-Load architecture, AI proxy technology, transparent proxy principles, microservice architecture, Go language"
      }
    }
  },
  "keyManagement": {
    "title": "Intelligent Key Management",
    "subtitle": "GPT-Load employs intelligent key management mechanisms through polling load balancing, automatic failure detection, and recovery mechanisms to ensure high service availability and stability.",
    "polling": {
      "title": "Polling Mechanism",
      "objective": {
        "title": "Objective",
        "description": "Achieve fair load balancing for requests among multiple keys within a group."
      },
      "implementation": {
        "title": "Implementation",
        "atomicCounter": {
          "title": "Atomic Counter",
          "description": "Ensures polling consistency and fairness under high concurrency"
        },
        "statusFilter": {
          "title": "Status Filtering",
          "description": "Polling scope limited to keys with 'valid' status within the group"
        }
      }
    },
    "retry": {
      "title": "Retry & Failure Handling",
      "trigger": {
        "title": "Trigger Scenarios",
        "description": "Automatically triggered when request fails (HTTP Status ‚â• 400 or network errors)"
      },
      "process": {
        "title": "Processing Flow",
        "step1": {
          "title": "Mark Failure",
          "description": "Increment failure count for the current failed key"
        },
        "step2": {
          "title": "Get New Key",
          "description": "Immediately obtain the next available key within the group through polling"
        },
        "step3": {
          "title": "Transparent Retry",
          "description": "Retry request with new key, transparent to client"
        },
        "step4": {
          "title": "Retry Limit",
          "description": "Configured maximum retry attempts. If all attempts fail, return final error to client"
        }
      }
    },
    "blacklist": {
      "title": "Key Blacklisting & Recovery",
      "mechanism": {
        "title": "Blacklisting Mechanism",
        "trigger": {
          "title": "Trigger Condition",
          "description": "When a key's cumulative failure count reaches the blacklist threshold"
        },
        "actions": {
          "title": "Actions Taken",
          "items": [
            "Key status updated to 'invalid'",
            "Removed from polling queue, no longer receives new requests"
          ]
        }
      }
    },
    "recovery": {
      "title": "Recovery Mechanism",
      "timing": {
        "title": "Trigger Timing",
        "description": "Background scheduled task executed at key validation intervals"
      },
      "process": {
        "title": "Recovery Process",
        "step1": {
          "title": "Health Check",
          "description": "Use blacklisted key to request validation endpoint (e.g., models list)"
        },
        "step2": {
          "title": "Validation Success",
          "items": [
            "Key status restored to 'valid'",
            "Failure count reset to 0",
            "Re-added to polling queue"
          ]
        },
        "step3": {
          "title": "Validation Failure",
          "description": "Maintain 'invalid' status, wait for next check cycle"
        }
      }
    },
    "advantages": {
      "title": "Mechanism Advantages",
      "loadBalancing": {
        "title": "Load Balancing",
        "description": "Atomic counter ensures fair polling under high concurrency"
      },
      "autoRecovery": {
        "title": "Auto Recovery",
        "description": "Scheduled health checks and automatic recovery of failed keys"
      },
      "faultIsolation": {
        "title": "Fault Isolation",
        "description": "Quickly identify failed keys to ensure service stability"
      }
    }
  },
  "routingStrategy": {
    "title": "Routing Strategy",
    "subtitle": "Understand GPT-Load's path processing mechanism, master flexible path configuration methods to ensure proper connection between clients and upstream services.",
    "coreProcessing": {
      "title": "Path Processing Principles",
      "transparentPrinciple": {
        "title": "Transparent Principle",
        "description": "GPT-Load follows the transparent principle, only responsible for path replacement while maintaining maximum flexibility. The core logic is to replace the proxy prefix in client requests with the actual upstream address.",
        "rule": "Replacement Rule: GPT-Load Service Address + /proxy/ + Group Name    Replaced with    Upstream Address"
      }
    },
    "processingFlow": {
      "title": "Processing Flow Example",
      "serviceAddress": "Service Address",
      "upstreamAddress": "Upstream Address",
      "groupName": "Group Name",
      "clientRequest": "Client Request",
      "actualRequest": "Actual Request"
    },
    "configurationMethods": {
      "title": "Configuration Methods",
      "description": "Using OpenRouter as an example (full path: https://openrouter.ai/api/v1/chat/completions), group name is openrouter, channel type is openai:",
      "method1": {
        "title": "Configuration Method 1: Domain Separation",
        "gptLoadConfig": "GPT-Load Configuration",
        "upstreamAddress": "Upstream Address",
        "testPath": "Test Path",
        "clientConfig": "Client Configuration",
        "cherryStudioApi": "Cherry Studio API Address"
      },
      "method2": {
        "title": "Configuration Method 2: Include API Path (Recommended)",
        "gptLoadConfig": "GPT-Load Configuration",
        "upstreamAddress": "Upstream Address",
        "testPath": "Test Path",
        "clientConfig": "Client Configuration",
        "cherryStudioApi": "Cherry Studio API Address"
      },
      "method3": {
        "title": "Configuration Method 3: Complete Version Path",
        "gptLoadConfig": "GPT-Load Configuration",
        "upstreamAddress": "Upstream Address",
        "testPath": "Test Path",
        "clientConfig": "Client Configuration",
        "cherryStudioApi": "Cherry Studio API Address",
        "note": "Note: Must end with /, avoid client auto-appending v1 path"
      }
    },
    "bestPractices": {
      "title": "Best Practices",
      "configurationSuggestions": {
        "title": "Configuration Suggestions",
        "items": [
          "‚Ä¢ Recommend using configuration method 2 for clear structure",
          "‚Ä¢ First determine the complete upstream API address",
          "‚Ä¢ Choose appropriate path split point based on client characteristics",
          "‚Ä¢ Maintain configuration consistency and maintainability"
        ]
      },
      "debuggingTips": {
        "title": "Debugging Tips",
        "items": [
          "‚Ä¢ Check GPT-Load request logs to confirm upstream address",
          "‚Ä¢ Use test path to verify configuration correctness",
          "‚Ä¢ Pay attention to client path concatenation rules",
          "‚Ä¢ Flexibly adjust configuration to adapt to different scenarios"
        ]
      }
    },
    "summary": {
      "title": "Configuration Summary",
      "description": "Understanding path processing logic is key: GPT-Load only handles simple string replacement, flexible configuration methods can adapt to various client and upstream service needs.",
      "corePrinciple": "Core Principle",
      "principle": "Ensure that test address and client request address, after GPT-Load proxy, reach the correct upstream address."
    }
  },
  "channels": {
    "title": "Channel Types",
    "subtitle": "GPT-Load supports multiple mainstream AI service providers, offering completely transparent proxy access while maintaining native API format and experience.",
    "supportedServices": {
      "title": "Supported Services",
      "openai": {
        "title": "OpenAI",
        "features": [
          "Chat Completions API",
          "Embeddings API",
          "Images API",
          "Audio API",
          "Files API",
          "Models API"
        ]
      },
      "gemini": {
        "title": "Google Gemini",
        "features": [
          "Generate Content API",
          "Streaming Support",
          "Multi-modal Inputs",
          "Safety Settings",
          "Generation Config",
          "Models Management"
        ]
      },
      "claude": {
        "title": "Anthropic Claude",
        "features": [
          "Messages API",
          "Streaming Responses",
          "System Prompts",
          "Tool Use",
          "Token Counting",
          "Models Access"
        ]
      },
      "extensibility": {
        "title": "Extensibility",
        "description": "Architecture designed to quickly add new AI service providers through standardized interface adaptation layer for unified access."
      }
    },
    "proxyFormat": {
      "title": "Proxy Format",
      "unifiedEndpoint": {
        "title": "Unified Proxy Endpoint",
        "format": "http://localhost:3001/proxy/{group-name}"
      },
      "parameters": {
        "title": "Parameter Description",
        "items": [
          "group-name: Group name created in the management interface",
          "Supports arbitrary path suffixes with complete transparent forwarding",
          "Maintains all functionality of the original API"
        ]
      },
      "authentication": {
        "title": "Authentication",
        "items": [
          "Use original service's API Key",
          "Pass through Authorization: Bearer {token} header",
          "Supports group-level key rotation and load balancing"
        ]
      }
    },
    "openaiFormat": {
      "title": "OpenAI Format Integration",
      "authentication": {
        "title": "Authentication Configuration",
        "description": "GPT-Load is fully compatible with OpenAI SDK, only need to change base_url for seamless switching."
      },
      "examples": {
        "original": {
          "title": "Original OpenAI Request",
          "code": "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4\",\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'"
        },
        "proxy": {
          "title": "Via GPT-Load Proxy",
          "code": "curl http://localhost:3001/proxy/openai/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4\",\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'"
        }
      },
      "migration": {
        "step1": "Only need to change API base address, all other code remains unchanged",
        "step2": "Supports all OpenAI SDK functionality"
      },
      "endpoints": {
        "title": "Supported Endpoints",
        "main": {
          "title": "Core APIs",
          "items": [
            "/v1/chat/completions - Chat completions",
            "/v1/embeddings - Vector embeddings",
            "/v1/images/generations - Image generation",
            "/v1/audio/speech - Text-to-speech",
            "/v1/audio/transcriptions - Speech-to-text"
          ]
        },
        "other": {
          "title": "Other APIs",
          "items": [
            "/v1/models - Model listing",
            "/v1/files - File management",
            "/v1/fine_tuning/jobs - Fine-tuning jobs",
            "/v1/assistants - Assistants API",
            "/v1/threads - Conversation threads"
          ]
        }
      },
      "sdk": {
        "title": "SDK Configuration",
        "python": {
          "title": "Python SDK",
          "code": "from openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"your-openai-api-key\",\n    base_url=\"http://localhost:3001/proxy/openai\"\n)\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ]\n)"
        },
        "nodejs": {
          "title": "Node.js SDK",
          "code": "import OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: 'your-openai-api-key',\n  baseURL: 'http://localhost:3001/proxy/openai'\n});\n\nconst response = await openai.chat.completions.create({\n  model: 'gpt-4',\n  messages: [\n    { role: 'user', content: 'Hello!' }\n  ]\n});"
        }
      }
    },
    "geminiFormat": {
      "title": "Gemini Format Integration",
      "authentication": {
        "title": "Authentication Configuration",
        "description": "Fully compatible with Google Gemini API, supporting all native features including multi-modal inputs and streaming responses."
      },
      "examples": {
        "original": {
          "title": "Original Gemini Request",
          "code": "curl https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=$API_KEY \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"contents\": [{\n      \"parts\": [{\n        \"text\": \"Write a story about a magic backpack.\"\n      }]\n    }]\n  }'"
        },
        "proxy": {
          "title": "Via GPT-Load Proxy",
          "code": "curl http://localhost:3001/proxy/gemini/v1beta/models/gemini-pro:generateContent?key=$API_KEY \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"contents\": [{\n      \"parts\": [{\n        \"text\": \"Write a story about a magic backpack.\"\n      }]\n    }]\n  }'"
        }
      },
      "migration": {
        "step1": "Replace request base address with GPT-Load proxy address",
        "step2": "Keep all parameters and authentication methods unchanged"
      },
      "endpoints": {
        "title": "Supported Endpoints",
        "content": {
          "title": "Content Generation",
          "items": [
            "/v1beta/models/*/generateContent - Content generation",
            "/v1beta/models/*/streamGenerateContent - Streaming generation",
            "/v1beta/models/*/countTokens - Token counting",
            "/v1beta/models/*/embedContent - Vector embeddings"
          ]
        },
        "models": {
          "title": "Model Management",
          "items": [
            "/v1beta/models - Model listing",
            "/v1beta/models/* - Model details",
            "/v1beta/tuning/createTunedModel - Fine-tuning creation",
            "/v1beta/tuning/tunedModels - Fine-tuning list"
          ]
        }
      },
      "sdk": {
        "title": "SDK Configuration",
        "python": {
          "title": "Python SDK",
          "code": "import google.generativeai as genai\n\n# Configure API Key\ngenai.configure(\n    api_key=\"your-gemini-api-key\",\n    client_options={\"api_endpoint\": \"http://localhost:3001/proxy/gemini\"}\n)\n\nmodel = genai.GenerativeModel('gemini-pro')\nresponse = model.generate_content(\"Hello!\")"
        },
        "http": {
          "title": "HTTP Request",
          "code": "POST http://localhost:3001/proxy/gemini/v1beta/models/gemini-pro:generateContent?key=YOUR_API_KEY\nContent-Type: application/json\n\n{\n  \"contents\": [{\n    \"parts\": [{\n      \"text\": \"Explain how AI works\"\n    }]\n  }]\n}"
        }
      }
    },
    "claudeFormat": {
      "title": "Claude Format Integration",
      "authentication": {
        "title": "Authentication Configuration",
        "description": "Fully compatible with Anthropic Claude API, supporting Messages API, tool usage, streaming responses and all advanced features."
      },
      "examples": {
        "original": {
          "title": "Original Claude Request",
          "code": "curl https://api.anthropic.com/v1/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -d '{\n    \"model\": \"claude-3-sonnet-20240229\",\n    \"max_tokens\": 1024,\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n    ]\n  }'"
        },
        "proxy": {
          "title": "Via GPT-Load Proxy",
          "code": "curl http://localhost:3001/proxy/claude/v1/messages \\\n  -H \"Content-Type: application/json\" \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -d '{\n    \"model\": \"claude-3-sonnet-20240229\",\n    \"max_tokens\": 1024,\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n    ]\n  }'"
        }
      },
      "migration": {
        "step1": "Update API base address to GPT-Load proxy endpoint",
        "step2": "Keep all headers and request format unchanged"
      },
      "endpoints": {
        "title": "Supported Endpoints",
        "main": {
          "title": "Core APIs",
          "items": [
            "/v1/messages - Message conversations",
            "/v1/messages/streaming - Streaming conversations",
            "/v1/complete - Text completion (Legacy)",
            "/v1/tools - Tool usage"
          ]
        },
        "models": {
          "title": "Model Management",
          "items": [
            "/v1/models - Available model list",
            "Supports full Claude-3 model series",
            "Supports custom max_tokens limits",
            "Supports system prompt configuration"
          ]
        }
      },
      "sdk": {
        "title": "SDK Configuration",
        "python": {
          "title": "Python SDK",
          "code": "from anthropic import Anthropic\n\nclient = Anthropic(\n    api_key=\"your-claude-api-key\",\n    base_url=\"http://localhost:3001/proxy/claude\"\n)\n\nmessage = client.messages.create(\n    model=\"claude-3-sonnet-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ]\n)"
        },
        "http": {
          "title": "HTTP Request",
          "code": "POST http://localhost:3001/proxy/claude/v1/messages\nContent-Type: application/json\nx-api-key: YOUR_API_KEY\nanthropic-version: 2023-06-01\n\n{\n  \"model\": \"claude-3-sonnet-20240229\",\n  \"max_tokens\": 1024,\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ]\n}"
        }
      }
    },
    "groupManagement": {
      "title": "Group Management",
      "creation": {
        "title": "Creating Groups",
        "steps": [
          "Access GPT-Load management interface",
          "Navigate to \"Environment Management\" -> \"Group Settings\"",
          "Click \"Add Group\" and fill in group information",
          "Select corresponding channel type (OpenAI/Gemini/Claude)",
          "Configure upstream address and test path",
          "Add API keys and test connection",
          "Save configuration and enable group"
        ]
      },
      "configuration": {
        "title": "Configuration Points",
        "items": [
          "Group name becomes part of the proxy path",
          "Supports multiple API keys per group",
          "Automatic key rotation and load balancing",
          "Supports key health checks and failover",
          "Can set request rate limits and quota management"
        ]
      }
    },
    "migration": {
      "title": "Migration Guide",
      "guide": {
        "title": "Migration Steps",
        "steps": [
          {
            "title": "Assess Current State",
            "description": "Analyze current AI services and API calling methods"
          },
          {
            "title": "Deploy GPT-Load",
            "description": "Deploy GPT-Load service following the quick start guide"
          },
          {
            "title": "Update Configuration",
            "description": "Modify API base addresses in applications to point to GPT-Load"
          }
        ]
      },
      "seamless": {
        "title": "Seamless Migration",
        "description": "GPT-Load's design philosophy is complete transparency. During migration, no business logic modification is needed, just change API endpoint addresses to enjoy unified management and load balancing benefits."
      }
    },
    "summary": {
      "title": "Summary",
      "transparent": {
        "title": "Transparent Proxy",
        "features": [
          "Maintains native API format",
          "No need to modify business code",
          "Supports all functionality"
        ]
      },
      "unified": {
        "title": "Unified Management",
        "features": [
          "Multi-service unified access",
          "Centralized key management",
          "Unified monitoring and alerting"
        ]
      },
      "scalable": {
        "title": "Highly Scalable",
        "features": [
          "Load balancing and failover",
          "Horizontal scaling support",
          "Enterprise-grade performance"
        ]
      }
    }
  },
  "performance": {
    "title": "Performance Details",
    "subtitle": "GPT-Load adopts a \"proxy path first\" high-performance design philosophy, where all optimizations ensure ultimate performance and stability of core proxy requests.",
    "coreFeatures": {
      "title": "Core Performance Features",
      "zeroIO": {
        "title": "Zero I/O Operations",
        "description": "Full in-memory proxy request processing"
      },
      "zeroCopy": {
        "title": "Zero-Copy Streaming",
        "description": "Direct streaming data forwarding"
      },
      "lockFree": {
        "title": "Lock-Free Concurrency",
        "description": "Efficient atomic operation processing"
      },
      "lowResource": {
        "title": "Ultra-Low Resource Usage",
        "description": "Single core 128MB memory operation"
      }
    },
    "proxyPerformance": {
      "title": "Ultimate Proxy Request Performance",
      "description": "To achieve minimum latency and maximum concurrency, the core path of proxy requests is designed as \"zero I/O operations\".",
      "inMemory": {
        "title": "Full In-Memory Service",
        "description": "All data required for routing and decision-making, including group configurations and key information, are preloaded into memory during service startup and configuration changes. No database or disk access is needed during proxy requests."
      },
      "zeroCopyStreaming": {
        "title": "Zero-Copy Streaming",
        "mechanism": {
          "title": "Real-time Transparent Transmission Mechanism",
          "description": "GPT-Load adopts real-time transparent transmission mode, directly connecting upstream service data streams to client responses without any intermediate buffering, line-by-line reading, or content parsing."
        },
        "comparison": {
          "title": "Difference from Traditional Streaming Processing",
          "traditional": {
            "label": "‚ùå Traditional Approach",
            "flow": "Line reading ‚Üí Parse processing ‚Üí Buffer output"
          },
          "gptLoad": {
            "label": "‚úÖ GPT-Load Approach",
            "flow": "Upstream data stream ‚Üí Direct transmission ‚Üí Client"
          }
        },
        "advantages": {
          "title": "Core Advantages",
          "leftColumn": [
            {
              "title": "Avoid Data Packet Truncation",
              "description": "Won't damage original data packet structure due to line-by-line reading"
            },
            {
              "title": "Ultimate Compatibility",
              "description": "Naturally supports all data formats including SSE, JSON streams, binary, etc."
            },
            {
              "title": "Unlimited Response Capability",
              "description": "Theoretically can handle upstream response data of any size"
            }
          ],
          "rightColumn": [
            {
              "title": "Zero-Latency Transmission",
              "description": "Data forwarded immediately upon arrival, no buffer waiting time"
            },
            {
              "title": "Ultra-Low Memory Usage",
              "description": "No data caching, memory usage independent of response size"
            },
            {
              "title": "Native Performance Experience",
              "description": "Response speed infinitely close to upstream service native performance"
            }
          ]
        }
      },
      "asyncLogging": {
        "title": "Asynchronous Logging",
        "description": "Request logging uses delayed asynchronous write strategy, completely decoupled from request-response lifecycle, ensuring logging operations don't interfere with real-time proxy performance."
      }
    },
    "resourceManagement": {
      "title": "Dynamic Resource & Concurrency Management",
      "httpReuse": {
        "title": "Efficient HTTP Client Reuse",
        "features": [
          "Maintain independent HTTP client instances with reusable underlying connections for each group",
          "When group configurations (like timeouts) change, system dynamically generates new client instances in real-time to ensure immediate configuration effectiveness"
        ]
      },
      "atomicOperations": {
        "title": "Atomic Operations & Lock-Free Design",
        "description": "In high-frequency concurrent operations like key polling counting, use sync/atomic package for lock-free programming, avoiding performance overhead from mutex locks."
      }
    },
    "asyncTasks": {
      "title": "Asynchronous Tasks & Scalability",
      "massiveKeys": {
        "title": "Asynchronous Management of Massive Keys",
        "mechanism": {
          "title": "Mechanism",
          "description": "Operations like adding and validating keys are all executed as asynchronous background tasks."
        },
        "advantage": {
          "title": "Advantage",
          "description": "Management operations don't block service, theoretically allowing system to manage millions of keys."
        }
      },
      "clusterSupport": {
        "title": "Cluster Support & Configuration Synchronization",
        "architecture": {
          "title": "Architecture",
          "description": "Supports multi-node Master-Slave architecture for horizontal scaling."
        },
        "sync": {
          "title": "Synchronization",
          "redis": "Master node configuration changes pushed via Redis Pub/Sub notifications",
          "consistency": "Slave nodes listen and pull updates through built-in configuration synchronizer, achieving eventual consistency across cluster configurations"
        }
      }
    },
    "lightweight": {
      "title": "Lightweight & Resource Efficiency",
      "lowResource": {
        "title": "Ultra-Low Resource Usage",
        "description": "Thanks to Go language's efficient memory management and the above performance optimizations (like zero-copy, connection pool reuse), GPT-Load runs as a compiled binary with no additional runtime dependencies, achieving ultra-low resource usage.",
        "cpu": "Single core CPU",
        "memory": "128MB memory"
      },
      "versatility": {
        "title": "Wide Applicability",
        "description": "In typical single-machine deployment scenarios, only low CPU and memory are needed to ensure smooth service operation.",
        "scenarios": [
          "Capable of handling high-concurrency scenarios for large enterprises",
          "Suitable for resource-limited personal developer environments"
        ]
      }
    }
  },
  "configurationPage": {
    "title": "Configuration",
    "subtitle": "GPT-Load adopts a powerful and flexible three-tier configuration system to meet configuration needs in different scenarios",
    "threeLayerArchitecture": {
      "title": "Three-Tier Configuration System Architecture",
      "priorityTitle": "Configuration Priority",
      "groupConfig": {
        "name": "Group Configuration",
        "priority": "Highest Priority"
      },
      "systemSettings": {
        "name": "System Settings",
        "priority": "Medium Priority"
      },
      "environmentVars": {
        "name": "Environment Variables",
        "priority": "Base Priority"
      },
      "managerDescription": "The configuration system uses",
      "managerFunction": "to manage configuration loading, merging, and hot updates"
    },
    "features": {
      "title": "Configuration Features",
      "items": [
        "‚Ä¢ <strong>Three-Tier Architecture</strong>: Environment, system, group",
        "‚Ä¢ <strong>Priority Override</strong>: Upper layer overrides lower layer",
        "‚Ä¢ <strong>Hot Update Support</strong>: Runtime dynamic effect",
        "‚Ä¢ <strong>Configuration Validation</strong>: Strict data validation"
      ]
    },
    "useCases": {
      "title": "Use Cases",
      "items": [
        "‚Ä¢ <strong>Environment Configuration</strong>: Basic service parameters",
        "‚Ä¢ <strong>System Configuration</strong>: Global business settings",
        "‚Ä¢ <strong>Group Configuration</strong>: Specific group customization",
        "‚Ä¢ <strong>Dynamic Tuning</strong>: Real-time performance optimization"
      ]
    },
    "managementMethods": {
      "title": "Management Methods",
      "items": [
        "‚Ä¢ <strong>Environment Variables</strong>: .env files or system environment",
        "‚Ä¢ <strong>Web Management</strong>: Online configuration interface",
        "‚Ä¢ <strong>API Interface</strong>: Programmatic configuration management",
        "‚Ä¢ <strong>Configuration Files</strong>: JSON format import/export"
      ]
    },
    "bestPractices": {
      "title": "Best Practices",
      "recommendations": {
        "title": "Configuration Management Recommendations",
        "items": [
          "‚Ä¢ <strong>Unified Management</strong>: Recommend using the platform's Web interface for centralized management to ensure consistency.",
          "‚Ä¢ <strong>Regular Audits</strong>: Regularly review configurations, remove unused parameters to keep the system clean.",
          "‚Ä¢ <strong>Version Control</strong>: For important configuration changes, recommend recording in version control system for tracking and rollback."
        ]
      },
      "warnings": {
        "title": "Precautions",
        "items": [
          "‚Ä¢ <strong>Sensitive Information</strong>: Never store passwords, API keys and other sensitive information in project configuration, use environment variables instead.",
          "‚Ä¢ <strong>Careful Hot Updates</strong>: Hot update feature is powerful but should be used carefully to avoid unexpected behavior in production environment.",
          "‚Ä¢ <strong>Performance Impact</strong>: Frequent configuration changes may have slight impact on system performance, recommend operating during off-peak hours."
        ]
      }
    },
    "furtherReading": {
      "title": "Further Reading",
      "environment": {
        "title": "Environment Configuration",
        "description": "View infrastructure-level configuration through environment variables or .env files."
      },
      "project": {
        "title": "Project Configuration",
        "description": "Explore system-level and group-level dynamic configuration managed through database."
      },
      "cloudflareAiGateway": {
        "title": "Cloudflare AI Gateway",
        "description": "Configure Cloudflare AI Gateway as upstream proxy to optimize AI service performance."
      }
    }
  },
  "cloudflareAIGateway": {
    "title": "Cloudflare AI Gateway Upstream Configuration",
    "subtitle": "This guide will help you configure Cloudflare AI Gateway as GPT-Load's upstream proxy, optimizing AI service request performance and stability through Cloudflare's global network.",
    "importantNotice": {
      "title": "Important Notice",
      "description": "Cloudflare AI Gateway only supports certain AI service providers. Before configuration, please confirm that your required AI service channels are in Cloudflare's support list. If your channel is not available in the API platform dropdown list, then that channel is not available."
    },
    "step1": {
      "title": "Register and Login to Cloudflare",
      "dashboard": {
        "title": "Access Cloudflare Dashboard",
        "description": "Go to Cloudflare official website to register an account and login to the console"
      }
    },
    "step2": {
      "title": "Enter AI Gateway Management Page",
      "navigation": {
        "title": "Navigate to AI Gateway",
        "selectMenu": {
          "title": "Select Menu",
          "description": "In the left navigation bar, select in order: <strong>AI ‚Üí AI Gateway</strong>"
        },
        "accessPage": {
          "title": "Access Management Page",
          "description": "Enter the AI Gateway management page, where you can see the current gateway list"
        }
      },
      "screenshot": {
        "alt": "Cloudflare AI Gateway menu navigation screenshot"
      }
    },
    "step3": {
      "title": "Create AI Gateway",
      "createButton": {
        "title": "Click Create Gateway",
        "description": "On the AI Gateway page, click the <strong>&ldquo;Create Gateway&rdquo;</strong> button to start configuring a new gateway"
      },
      "configuration": {
        "title": "Configure Gateway Parameters",
        "gatewayName": {
          "title": "Set Gateway Name",
          "note": "The name can be set arbitrarily, here using &ldquo;gpt-load&rdquo; as an example"
        },
        "defaultSettings": {
          "title": "Keep Default Settings",
          "description": "Other configuration items can keep their default values"
        },
        "important": {
          "title": "Important Configuration Items",
          "items": [
            "‚Ä¢ <strong>Do not enable caching</strong> - CF's cache has bugs in some channels",
            "‚Ä¢ <strong>Do not enable gateway authentication</strong> - Keep authentication function disabled"
          ]
        }
      },
      "screenshot": {
        "alt": "Cloudflare AI Gateway creation form screenshot"
      }
    },
    "step4": {
      "title": "Get Channel Proxy Address",
      "endpoint": {
        "title": "View API Endpoints",
        "clickAPI": {
          "title": "Click API Button",
          "description": "After creation is complete, click the <strong>&ldquo;API&rdquo;</strong> button in the upper right corner"
        },
        "selectChannel": {
          "title": "Select Target Channel",
          "description": "Find your required AI service provider in the API platform dropdown list and copy the corresponding proxy address"
        },
        "note": "Each AI service provider has a corresponding proxy address, make sure to select the correct channel"
      },
      "screenshot": {
        "alt": "Cloudflare AI Gateway API endpoint list screenshot"
      }
    },
    "step5": {
      "title": "Configure to GPT-Load",
      "configuration": {
        "title": "Add Upstream Address",
        "copyAddress": {
          "title": "Copy Proxy Address",
          "description": "Copy the proxy address obtained from Cloudflare AI Gateway to the upstream address configuration of the corresponding group in GPT-Load"
        },
        "example": {
          "title": "Example Address:",
          "explanation": "Where <code className=\"bg-gray-100 px-1 rounded\">b7fbxxxxxfdba</code> is your account ID, <code className=\"bg-gray-100 px-1 rounded\">gpt-load</code> is the gateway name, <code className=\"bg-gray-100 px-1 rounded\">google-ai-studio</code> is the specific AI service provider"
        }
      },
      "screenshot": {
        "title": "GPT-Load Configuration Example",
        "alt": "GPT-Load configuring Cloudflare AI Gateway upstream address example screenshot"
      }
    },
    "geminiNotice": {
      "title": "Gemini Channel Special Notice",
      "reminder": "Important Reminder",
      "description": "When using Gemini channel type with Cloudflare AI Gateway:",
      "items": [
        "<strong>Recommended:</strong> Use Gemini native format calls, works normally",
        "<strong>Not recommended:</strong> Use Gemini official OpenAI format calls, may cause garbled output issues"
      ],
      "recommendation": "This is a known issue with Cloudflare AI Gateway, it is recommended to always use Gemini native format to ensure optimal compatibility."
    },
    "networkNotice": {
      "title": "Network Routing Issue Reminder",
      "regionalBlock": "About Regional Blocking Reminder",
      "description1": "If your GPT-Load server is located in mainland China or Hong Kong, Cloudflare may route requests to Hong Kong nodes.",
      "description2": "Since many AI service providers (such as OpenAI) do not support this region, this may cause",
      "description3": "errors.",
      "solution": "If you encounter this issue, please adjust your server's network environment and retry."
    },
    "verification": {
      "title": "Verify Configuration",
      "testConnection": "Test Connection",
      "description": "After configuration is complete, send a test request to confirm the proxy is working properly. If you encounter problems, please check the Cloudflare AI Gateway status and GPT-Load configuration for correctness."
    },
    "relatedResources": {
      "title": "Related Resources",
      "officialDocs": "Cloudflare AI Gateway Official Documentation",
      "gptLoadConfig": "GPT-Load Configuration Guide",
      "channelTypes": "Channel Types Guide"
    }
  },
  "managementPage": {
    "title": "Group Configuration Management",
    "subtitle": "Complete guide for group creation and configuration, including detailed configuration instructions for basic settings, upstream addresses, advanced settings and other features",
    "basicConfig": {
      "title": "Basic Configuration",
      "groupName": {
        "label": "Group Name",
        "description": "Unique identifier for the group, used for internal system identification and management. Recommend using meaningful naming"
      },
      "displayName": {
        "label": "Display Name",
        "description": "Friendly display name for the group, used for frontend interface display to improve readability"
      },
      "channelType": {
        "label": "Channel Type",
        "description": "Type identifier of upstream service, determines API compatibility and request format"
      },
      "testModel": {
        "label": "Test Model",
        "description": "Model name used for connection testing to ensure configuration correctness"
      },
      "proxyKey": {
        "label": "Proxy Key",
        "description": "System-generated proxy key for API access authentication, supports generation and copy operations"
      },
      "priority": {
        "label": "Priority Weight",
        "description": "Priority weight of the group, higher values have higher priority, affecting load balancing strategy"
      }
    },
    "upstreamConfig": {
      "title": "Upstream Address Configuration",
      "multiAddress": {
        "title": "Multi-Address Load Balancing",
        "description": "Supports configuring multiple upstream addresses for load distribution and high availability. Note: Multiple addresses should be different access points of the same service, not different service providers.",
        "loadBalancing": "Weight-based round-robin algorithm distributes requests",
        "sameService": "All addresses must be different nodes of the same upstream service",
        "weightRoundRobin": "Supports weighted round-robin for intelligent load distribution"
      },
      "configuration": {
        "title": "Configuration Examples",
        "weight1": "Weight: 1 (Primary address)",
        "weight2": "Weight: 1 (Backup address)"
      },
      "features": {
        "title": "Feature Advantages",
        "highAvailability": "High availability: Automatic switching during single point failures",
        "autoFailover": "Automatic failover: Abnormal nodes automatically removed",
        "performance": "Performance optimization: Nearby node access improves response speed",
        "monitoring": "Real-time monitoring: Node status and response time monitoring"
      }
    },
    "advancedConfig": {
      "title": "Advanced Configuration",
      "groupOverride": {
        "title": "Group Configuration Override",
        "description": "Group-level configuration parameters with higher priority than global system configuration. Unconfigured parameters will use system defaults.",
        "priority": {
          "title": "Configuration Priority",
          "group": "Group Configuration (Highest priority)",
          "system": "System Configuration (Medium priority)",
          "default": "Default Configuration (Lowest priority)"
        },
        "reference": {
          "title": "Reference Documentation",
          "description": "For detailed overridable configuration items, please refer to the project configuration page"
        }
      },
      "customHeaders": {
        "title": "Custom Request Headers",
        "functionality": {
          "title": "Functionality",
          "add": "Add custom HTTP request headers",
          "remove": "Remove existing request header fields",
          "modify": "Modify existing request header values"
        },
        "examples": {
          "title": "Configuration Examples",
          "auth": "Authorization: Bearer custom-token",
          "userAgent": "User-Agent: GPT-Load/1.0"
        }
      },
      "parameterOverride": {
        "title": "Parameter Override",
        "description": "Advanced JSON format request parameter override functionality for forcibly overriding specific parameters in user requests. Once configured, it will automatically merge into all requests.",
        "format": {
          "title": "JSON Format"
        },
        "useCases": {
          "title": "Use Cases",
          "defaultParams": "Set default parameter values",
          "limitParams": "Limit parameter ranges",
          "securityParams": "Force security parameters"
        }
      }
    },
    "bestPractices": {
      "title": "Configuration Best Practices",
      "configuration": {
        "title": "Configuration Management",
        "testing": "Validate in test environment before configuration changes",
        "backup": "Backup current settings before important configuration changes",
        "validation": "Use test functionality to validate configuration effectiveness"
      },
      "security": {
        "title": "Security Recommendations",
        "keyRotation": "Regular API key rotation to ensure security",
        "accessControl": "Restrict management interface access permissions",
        "monitoring": "Monitor abnormal access and error logs"
      }
    }
  },
  "environmentConfiguration": {
    "title": "Environment Configuration",
    "characteristics": {
      "title": "Configuration Features",
      "loadingMethod": {
        "title": "Loading Method",
        "items": [
          "‚Ä¢ Through environment variables or .env files",
          "‚Ä¢ One-time read at application startup",
          "‚Ä¢ Cannot be modified at runtime",
          "‚Ä¢ Provides basic configuration defaults"
        ]
      },
      "useCase": {
        "title": "Use Cases",
        "items": [
          "‚Ä¢ Server basic parameter configuration",
          "‚Ä¢ Database connection information",
          "‚Ä¢ Security authentication keys",
          "‚Ä¢ Logging and monitoring settings"
        ]
      }
    },
    "serverConfig": {
      "title": "Server Configuration",
      "table": {
        "configItem": "Configuration Item",
        "envVar": "Environment Variable",
        "defaultValue": "Default Value",
        "description": "Description"
      },
      "items": [
        {
          "name": "Service Port",
          "envVar": "PORT",
          "defaultValue": "3001",
          "description": "HTTP server listening port"
        },
        {
          "name": "Service Address",
          "envVar": "HOST",
          "defaultValue": "0.0.0.0",
          "description": "HTTP server binding address"
        },
        {
          "name": "Read Timeout",
          "envVar": "SERVER_READ_TIMEOUT",
          "defaultValue": "60",
          "description": "HTTP server read timeout (seconds)"
        },
        {
          "name": "Write Timeout",
          "envVar": "SERVER_WRITE_TIMEOUT",
          "defaultValue": "600",
          "description": "HTTP server write timeout (seconds)"
        },
        {
          "name": "Idle Timeout",
          "envVar": "SERVER_IDLE_TIMEOUT",
          "defaultValue": "120",
          "description": "HTTP connection idle timeout (seconds)"
        },
        {
          "name": "Graceful Shutdown Timeout",
          "envVar": "SERVER_GRACEFUL_SHUTDOWN_TIMEOUT",
          "defaultValue": "10",
          "description": "Service graceful shutdown wait time (seconds)"
        },
        {
          "name": "Slave Node Mode",
          "envVar": "IS_SLAVE",
          "defaultValue": "false",
          "description": "Slave node identifier for cluster deployment"
        },
        {
          "name": "Timezone",
          "envVar": "TZ",
          "defaultValue": "Asia/Shanghai",
          "description": "Specify timezone"
        }
      ]
    },
    "authDatabaseConfig": {
      "title": "Authentication & Database Configuration",
      "table": {
        "configItem": "Configuration Item",
        "envVar": "Environment Variable",
        "defaultValue": "Default Value",
        "description": "Description"
      },
      "items": [
        {
          "name": "Admin Key",
          "envVar": "AUTH_KEY",
          "defaultValue": "sk-123456",
          "description": "Admin access authentication key, please change to a strong password"
        },
        {
          "name": "Database Connection",
          "envVar": "DATABASE_DSN",
          "defaultValue": "./data/gpt-load.db",
          "description": "Database connection string (DSN) or file path"
        },
        {
          "name": "Redis Connection",
          "envVar": "REDIS_DSN",
          "defaultValue": "-",
          "description": "Redis connection string, use memory storage when empty"
        }
      ]
    },
    "performanceCorsConfig": {
      "title": "Performance & CORS Configuration",
      "table": {
        "configItem": "Configuration Item",
        "envVar": "Environment Variable",
        "defaultValue": "Default Value",
        "description": "Description"
      },
      "items": [
        {
          "name": "Max Concurrent Requests",
          "envVar": "MAX_CONCURRENT_REQUESTS",
          "defaultValue": "100",
          "description": "Maximum number of concurrent requests allowed by the system"
        },
        {
          "name": "Enable CORS",
          "envVar": "ENABLE_CORS",
          "defaultValue": "true",
          "description": "Whether to enable Cross-Origin Resource Sharing"
        },
        {
          "name": "Allowed Origins",
          "envVar": "ALLOWED_ORIGINS",
          "defaultValue": "*",
          "description": "Allowed origins, comma-separated"
        },
        {
          "name": "Allowed Methods",
          "envVar": "ALLOWED_METHODS",
          "defaultValue": "GET,POST,PUT,DELETE,OPTIONS",
          "description": "Allowed HTTP methods"
        },
        {
          "name": "Allowed Headers",
          "envVar": "ALLOWED_HEADERS",
          "defaultValue": "*",
          "description": "Allowed request headers, comma-separated"
        },
        {
          "name": "Allow Credentials",
          "envVar": "ALLOW_CREDENTIALS",
          "defaultValue": "false",
          "description": "Whether to allow sending credentials"
        }
      ]
    },
    "logConfig": {
      "title": "Log Configuration",
      "table": {
        "configItem": "Configuration Item",
        "envVar": "Environment Variable",
        "defaultValue": "Default Value",
        "description": "Description"
      },
      "items": [
        {
          "name": "Log Level",
          "envVar": "LOG_LEVEL",
          "defaultValue": "info",
          "description": "Log level: debug, info, warn, error"
        },
        {
          "name": "Log Format",
          "envVar": "LOG_FORMAT",
          "defaultValue": "text",
          "description": "Log format: text, json"
        },
        {
          "name": "Enable File Log",
          "envVar": "LOG_ENABLE_FILE",
          "defaultValue": "false",
          "description": "Whether to enable file log output"
        },
        {
          "name": "Log File Path",
          "envVar": "LOG_FILE_PATH",
          "defaultValue": "./data/logs/app.log",
          "description": "Log file storage path"
        }
      ]
    },
    "proxyConfig": {
      "title": "Proxy Configuration",
      "priority": {
        "title": "Priority Description",
        "description": "Proxy configuration supports three-tier priority:",
        "fallback": "Group Config > System Config > Environment Config",
        "envNote": "Environment proxy serves as global fallback configuration, only takes effect when neither system config nor group config has proxy settings."
      },
      "autoRead": "GPT-Load automatically reads proxy settings from environment variables for upstream AI service provider requests.",
      "settings": {
        "title": "Proxy Settings",
        "table": {
          "configItem": "Configuration Item",
          "envVar": "Environment Variable",
          "defaultValue": "Default Value",
          "description": "Description"
        },
        "items": [
          {
            "name": "HTTP Proxy",
            "envVar": "HTTP_PROXY",
            "defaultValue": "-",
            "description": "Proxy server address for HTTP requests"
          },
          {
            "name": "HTTPS Proxy",
            "envVar": "HTTPS_PROXY",
            "defaultValue": "-",
            "description": "Proxy server address for HTTPS requests"
          },
          {
            "name": "No Proxy",
            "envVar": "NO_PROXY",
            "defaultValue": "-",
            "description": "Hosts or domains that don't need proxy access, comma-separated"
          }
        ]
      },
      "formats": {
        "title": "Supported Protocol Formats",
        "items": [
          {
            "protocol": "HTTP",
            "format": "http://user:pass@host:port"
          },
          {
            "protocol": "HTTPS",
            "format": "https://user:pass@host:port"
          },
          {
            "protocol": "SOCKS5",
            "format": "socks5://user:pass@host:port"
          }
        ]
      }
    },
    "summary": {
      "title": "Environment Configuration Summary",
      "description": "Environment configuration is the foundation of the GPT-Load configuration system, primarily responsible for providing infrastructure parameters required for application operation.",
      "features": [
        "<strong>Basic Service Parameters</strong>: Defines core services that application startup and operation depend on, such as server ports, database connections, etc.",
        "<strong>Management Features</strong>: Configured through <code>.env</code> files or operating system environment variables, loaded at application startup, ensuring configuration stability and consistency.",
        "<strong>Usage Advantages</strong>: Provides reliable default values for the system while separating sensitive information (such as database passwords, API keys) from the codebase, enhancing security."
      ]
    }
  },
  "projectConfigurationPage": {
    "title": "Project Configuration",
    "systemSettings": {
      "title": "System Settings",
      "characteristics": {
        "title": "Configuration Features",
        "storage": {
          "title": "Storage Method",
          "database": "Stored in database",
          "dynamicModification": "Supports dynamic modification via management API",
          "hotReload": "Supports hot reload without restart",
          "baseline": "Provides behavioral baseline for the entire application"
        },
        "management": {
          "title": "Management Features",
          "webInterface": "Web interface visual configuration",
          "restfulApi": "RESTful API programmatic management",
          "validation": "Configuration validation and constraint checking",
          "history": "Change history tracking and rollback"
        }
      },
      "table": {
        "headers": {
          "configItem": "Configuration Item",
          "fieldName": "Field Name",
          "defaultValue": "Default Value",
          "groupOverridable": "Group Overridable",
          "description": "Description"
        }
      },
      "basicParameters": {
        "title": "Basic Parameters",
        "appUrl": {
          "name": "Project URL",
          "description": "Project base URL for concatenating group endpoints"
        },
        "proxyKeys": {
          "name": "Global Proxy Keys",
          "defaultValue": "Initial value is AUTH_KEY from environment config",
          "description": "Globally effective proxy authentication keys, separated by commas"
        },
        "logRetention": {
          "name": "Log Retention Days",
          "description": "Request log database retention days, 0 for no cleanup"
        },
        "logWriteInterval": {
          "name": "Log Write Interval",
          "description": "Log write to database cycle (minutes)"
        },
        "enableRequestBodyLogging": {
          "name": "Enable Log Details",
          "description": "Whether to record complete request body content in request logs, enabling will increase memory and storage usage"
        }
      },
      "requestSettings": {
        "title": "Request Settings",
        "requestTimeout": {
          "name": "Request Timeout",
          "description": "Complete lifecycle timeout for forwarded requests (seconds)"
        },
        "connectTimeout": {
          "name": "Connect Timeout",
          "description": "Connection establishment timeout with upstream service (seconds)"
        },
        "idleConnTimeout": {
          "name": "Idle Connection Timeout",
          "description": "HTTP client idle connection timeout (seconds)"
        },
        "responseHeaderTimeout": {
          "name": "Response Header Timeout",
          "description": "Timeout waiting for upstream response headers (seconds)"
        },
        "maxIdleConns": {
          "name": "Max Idle Connections",
          "description": "Maximum total idle connections in connection pool"
        },
        "maxIdleConnsPerHost": {
          "name": "Max Idle Connections Per Host",
          "description": "Maximum idle connections per upstream host"
        },
        "proxyUrl": {
          "name": "Proxy Server Address",
          "description": "HTTP/HTTPS proxy for forwarding requests, uses environment config if empty"
        }
      },
      "keyConfiguration": {
        "title": "Key Configuration",
        "maxRetries": {
          "name": "Max Retries",
          "description": "Maximum retry attempts for a single request using different keys"
        },
        "blacklistThreshold": {
          "name": "Blacklist Threshold",
          "description": "Number of consecutive failures before a key enters blacklist"
        },
        "keyValidationInterval": {
          "name": "Key Validation Interval",
          "description": "Background scheduled key validation cycle (minutes)"
        },
        "keyValidationConcurrency": {
          "name": "Key Validation Concurrency",
          "description": "Concurrency level for background scheduled validation of invalid keys"
        },
        "keyValidationTimeout": {
          "name": "Key Validation Timeout",
          "description": "API request timeout for background scheduled validation of individual keys (seconds)"
        }
      },
      "proxyConfigPriority": {
        "title": "Proxy Configuration Priority",
        "description": "System proxy configuration has medium priority, overrides environment variable config but can be overridden by group config:",
        "hierarchy": "Group Config > System Config > Environment Config",
        "fallback": "When proxy_url in system configuration is empty, environment variable proxy settings will be used automatically."
      }
    },
    "groupConfiguration": {
      "title": "Group Configuration",
      "characteristics": {
        "title": "Configuration Features",
        "highestPriority": {
          "title": "Highest Priority",
          "override": "Can override any parameter in system settings",
          "customize": "Customize dedicated behavior for specific groups",
          "tuning": "Supports fine-grained performance tuning",
          "isolation": "Implements multi-tenant isolated configuration",
          "proxyPriority": "Proxy configuration has highest priority, overrides system and environment settings"
        },
        "flexibility": {
          "title": "Configuration Flexibility",
          "jsonFormat": "Flexible configuration in JSON format",
          "inheritance": "Supports parameter override and inheritance",
          "dynamicCalculation": "Dynamic calculation of effective configuration",
          "validation": "Configuration validation and constraint checking"
        }
      },
      "overridableSettings": {
        "title": "Overridable Configuration Items",
        "requestConnection": {
          "title": "Request and Connection Configuration",
          "requestTimeout": "Request timeout",
          "connectTimeout": "Connect timeout",
          "idleConnTimeout": "Idle connection timeout",
          "responseHeaderTimeout": "Response header timeout",
          "maxIdleConns": "Max idle connections",
          "maxIdleConnsPerHost": "Max idle connections per host",
          "proxyUrl": "Proxy server address"
        },
        "keyManagement": {
          "title": "Key Management Configuration",
          "maxRetries": "Max retries",
          "blacklistThreshold": "Blacklist threshold",
          "keyValidationInterval": "Key validation interval",
          "keyValidationConcurrency": "Key validation concurrency",
          "keyValidationTimeout": "Key validation timeout",
          "enableRequestBodyLogging": "Enable log details"
        }
      }
    },
    "summary": {
      "title": "Project Configuration Summary",
      "description": "Project configuration is the core of GPT-Load configuration system, providing powerful dynamic management capabilities covering system-level and group-level configuration.",
      "roleAndLayering": {
        "title": "Role and Layering",
        "description": "Divided into \"System Settings\" and \"Group Configuration\", the former as global baseline, the latter providing overrides for specific scenarios, implementing hierarchical management."
      },
      "managementFeatures": {
        "title": "Management Features",
        "description": "Supports dynamic modification through Web interface and API, configuration changes can be hot-reloaded without service restart, ensuring high system availability."
      },
      "proxyConfigPriority": {
        "title": "Proxy Configuration Priority",
        "description": "Group Config > System Config > Environment Config, implementing flexible proxy settings from global to specific groups."
      },
      "usageAdvantages": {
        "title": "Usage Advantages",
        "description": "Provides extremely high flexibility and dynamic adjustment capabilities, allowing fine-grained isolation and optimization for different business scenarios (such as multi-tenancy)."
      }
    }
  },
  "deploymentPage": {
    "title": "Deployment Guide",
    "subtitle": "GPT-Load provides multiple deployment options to meet different scenario requirements. From lightweight standalone deployment to enterprise-grade cluster deployment, choose the most suitable solution for you.",
    "viewDetails": "View Details",
    "standalone": {
      "title": "Standalone Deployment",
      "subtitle": "Lightweight deployment for individuals and small teams",
      "quickStart": {
        "title": "Quick Start",
        "description": "One-click deployment with Docker Compose, SQLite + memory storage"
      },
      "optional": {
        "title": "Optional Deployment",
        "description": "Configure MySQL/PostgreSQL and Redis for improved performance"
      }
    },
    "source": {
      "title": "Source Code Deployment",
      "subtitle": "Developer-friendly, fully customizable",
      "fullControl": {
        "title": "Full Control",
        "description": "Customize build, configuration and deployment process"
      },
      "development": {
        "title": "Development Debugging",
        "description": "Suitable for development environments and feature customization"
      }
    },
    "cluster": {
      "title": "Cluster Deployment",
      "subtitle": "Enterprise-grade high availability solution",
      "masterSlave": {
        "title": "Master-Slave Architecture",
        "description": "Distributed deployment with horizontal scaling support"
      },
      "highAvailability": {
        "title": "High Availability",
        "description": "Failover and load balancing"
      }
    },
    "clawCloud": {
      "title": "Claw Cloud",
      "subtitle": "Free cloud deployment solution",
      "cloudDeploy": {
        "title": "Cloud Deploy",
        "description": "No server required, one-click deployment to cloud"
      },
      "freeQuota": {
        "title": "Free Quota",
        "description": "$5 free quota per month"
      }
    },
    "comparison": {
      "title": "Solution Comparison",
      "headers": {
        "solution": "Deployment Solution",
        "scenario": "Use Cases",
        "requirements": "Technical Requirements",
        "performance": "Performance",
        "complexity": "Operations Complexity"
      },
      "rows": {
        "standalone": {
          "solution": "Standalone Deployment",
          "scenario": "Personal, Small Teams",
          "requirements": "Docker Basics",
          "performance": "Medium",
          "complexity": "Simple"
        },
        "source": {
          "solution": "Source Code Deployment",
          "scenario": "Development & Debugging",
          "requirements": "Go Development Experience",
          "performance": "High",
          "complexity": "Medium"
        },
        "cluster": {
          "solution": "Cluster Deployment",
          "scenario": "Enterprise Production",
          "requirements": "K8s/Operations Experience",
          "performance": "Very High",
          "complexity": "Complex"
        },
        "clawCloud": {
          "solution": "Claw Cloud",
          "scenario": "Quick Experience",
          "requirements": "GitHub Account",
          "performance": "Medium",
          "complexity": "Simplest"
        }
      }
    },
    "gettingStarted": {
      "title": "Getting Started",
      "description": "If you are new to GPT-Load, we recommend starting with standalone deployment, which provides the best learning curve and quick experience.",
      "buttons": {
        "standalone": "Quick Standalone Deployment",
        "clawCloud": "Free Cloud Experience"
      }
    }
  },
  "cluster": {
    "title": "Cluster Deployment",
    "subtitle": "GPT-Load high availability cluster deployment solution with master-slave architecture and horizontal scaling support",
    "overview": {
      "title": "Cluster Architecture Overview",
      "architecture": {
        "title": "Distributed Master-Slave Architecture",
        "description": "Adopts a one-master-multiple-slave distributed architecture where the master node handles management functions and slave nodes focus on proxy services, achieving high availability and load distribution"
      },
      "components": {
        "master": {
          "title": "Master Node",
          "description": "Web management interface, configuration management, statistics analysis"
        },
        "slave": {
          "title": "Slave Node",
          "description": "Focused on API proxy services, supports horizontal scaling"
        },
        "storage": {
          "title": "Shared Storage",
          "description": "Unified MySQL and Redis cluster"
        }
      }
    },
    "prerequisites": {
      "title": "Deployment Requirements",
      "warning": {
        "title": "Important Notice",
        "description": "Database and Redis are required for cluster deployment, used for distributed coordination and state synchronization"
      },
      "infrastructure": {
        "title": "Infrastructure Requirements",
        "database": {
          "title": "Database Cluster",
          "items": [
            "‚Ä¢ MySQL 8.2+ high availability cluster",
            "‚Ä¢ Support master-slave replication or Galera cluster",
            "‚Ä¢ Recommended to configure read-write separation",
            "‚Ä¢ Regular backup and disaster recovery mechanisms"
          ]
        },
        "cache": {
          "title": "Cache Cluster",
          "items": [
            "‚Ä¢ Redis cluster or sentinel mode",
            "‚Ä¢ Used for distributed locks and state synchronization",
            "‚Ä¢ Configure persistence and failover",
            "‚Ä¢ Monitor memory usage and performance"
          ]
        }
      }
    },
    "deploymentSteps": {
      "title": "Deployment Steps",
      "step1": {
        "title": "Prepare Shared Infrastructure",
        "database": {
          "title": "Deploy MySQL Cluster (or PostgreSQL)",
          "description": "Recommend using cloud database cluster services or deploying independent MySQL/PostgreSQL clusters."
        },
        "redis": {
          "title": "Deploy Redis Cluster",
          "description": "Recommend using Redis Sentinel or cluster mode to ensure high availability and data consistency."
        }
      },
      "step2": {
        "title": "Node docker-compose.yml Reference (Same for Master and Slave)",
        "dockerCompose": "services:\n  gpt-load:\n    image: ghcr.io/tbphp/gpt-load:latest\n    container_name: gpt-load\n    ports:\n      - \"${PORT:-3001}:${PORT:-3001}\"\n    env_file:\n      - .env\n    restart: always\n    volumes:\n      - ./data:/app/data\n    stop_grace_period: ${SERVER_GRACEFUL_SHUTDOWN_TIMEOUT:-10}s\n    healthcheck:\n      test: wget -q --spider -T 10 -O /dev/null http://localhost:${PORT:-3001}/health\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s",
        "slaveConfig": {
          "title": "Use Configuration to Distinguish Master and Slave Nodes",
          "code": "IS_SLAVE=true",
          "description1": "Master node: not configured or set to IS_SLAVE=false. Slave node: set to IS_SLAVE=true.",
          "description2": "Ensure only one master node in the entire cluster."
        }
      },
      "step3": {
        "title": "Configure Load Balancing",
        "description": "Use Nginx or other load balancers to distribute requests to different slave nodes",
        "nginx": {
          "title": "Nginx Configuration Example",
          "config": "# nginx.conf\nupstream gpt_load_cluster {\n    server master-node-ip:3001 weight=3;\n    server slave-node1-ip:3001 weight=5;\n    server slave-node2-ip:3001 weight=5;\n    # Add more slave nodes as needed\n}\n\nserver {\n    listen 80;\n    server_name your-domain.com;\n\n    location / {\n        proxy_pass http://gpt_load_cluster;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # If using CF or other proxy services, set real IP\n        set_real_ip_from 0.0.0.0/0;\n        real_ip_header X-Forwarded-For;\n    }\n}"
        }
      }
    },
    "configurationManagement": {
      "title": "Configuration Management",
      "unified": {
        "title": "Unified Configuration Requirements",
        "items": [
          {
            "key": "AUTH_KEY",
            "description": "Must be the same (management key)"
          },
          {
            "key": "DATABASE_DSN",
            "description": "Must be the same"
          },
          {
            "key": "REDIS_DSN",
            "description": "Must be the same"
          },
          {
            "key": "IS_SLAVE",
            "description": "Set to true for slave nodes"
          }
        ]
      },
      "dynamic": {
        "title": "Dynamic Configuration Synchronization",
        "items": [
          "‚Ä¢ System settings stored in MySQL auto-sync",
          "‚Ä¢ Group configurations pushed to all nodes in real-time",
          "‚Ä¢ Key status shared through Redis in real-time",
          "‚Ä¢ Configuration changes require no service restart"
        ]
      }
    },
    "monitoring": {
      "title": "Monitoring and Operations",
      "healthCheck": {
        "title": "Health Check",
        "nodeStatus": {
          "title": "Node Health Status",
          "code": "# Check node status\ncurl http://node:3001/health\n\n# Response example\n{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2025-07-15T12:56:00Z\",\n  \"uptime\": \"11.822967ms\"\n}"
        },
        "clusterStatus": {
          "title": "Cluster Status Monitoring",
          "items": [
            "‚Ä¢ Monitor request volume and response time of each node",
            "‚Ä¢ Check database and Redis connection status"
          ]
        }
      },
      "scaling": {
        "title": "Scaling and Capacity Management",
        "scaleOut": {
          "title": "Horizontal Scaling",
          "items": [
            "‚Ä¢ Add slave nodes as needed",
            "‚Ä¢ Update load balancer configuration",
            "‚Ä¢ New nodes automatically sync configuration",
            "‚Ä¢ Seamlessly integrate with existing services"
          ]
        },
        "gracefulShutdown": {
          "title": "Graceful Shutdown",
          "items": [
            "‚Ä¢ Remove node from load balancer",
            "‚Ä¢ Wait for existing requests to complete",
            "‚Ä¢ Send stop signal to container",
            "‚Ä¢ Clean up related resources and logs"
          ]
        }
      }
    },
    "bestPractices": {
      "title": "Best Practices",
      "recommended": {
        "title": "‚úÖ Recommended Practices",
        "items": [
          "‚Ä¢ Use container orchestration tools (Docker Swarm/K8s)",
          "‚Ä¢ Configure high availability for database and Redis",
          "‚Ä¢ Set up comprehensive monitoring and alerting systems",
          "‚Ä¢ Regular backup of configurations and data",
          "‚Ä¢ Use configuration management tools for unified deployment",
          "‚Ä¢ Implement blue-green deployment or rolling updates"
        ]
      },
      "avoid": {
        "title": "‚ùå Practices to Avoid",
        "items": [
          "‚Ä¢ Single point of failure for database or cache",
          "‚Ä¢ Inconsistent configuration between nodes",
          "‚Ä¢ Ignoring network latency and partition issues",
          "‚Ä¢ Lack of monitoring and log collection",
          "‚Ä¢ Manual management of large numbers of node configurations",
          "‚Ä¢ Direct modification of production environment configuration"
        ]
      }
    }
  },
  "deployment": {
    "source": {
      "title": "Source Code Deployment",
      "subtitle": "Build and deploy GPT-Load from source code, suitable for developers to customize and debug features. Provides complete control and flexibility.",
      "prerequisites": {
        "title": "Environment Requirements",
        "development": {
          "title": "Development Environment",
          "description": "Requires local installation of Go development environment and related toolchain"
        },
        "required": {
          "title": "Required Software",
          "go": "Go 1.23+ development environment",
          "git": "Git version control tool",
          "make": "Make build tool",
          "database": "Database service (MySQL/PostgreSQL/SQLite)"
        },
        "optional": {
          "title": "Optional Software",
          "redis": "Redis cache service",
          "nodejs": "Node.js and npm (for frontend development)",
          "docker": "Docker (for containerized testing)",
          "ide": "IDE or editor (VS Code/GoLand)"
        }
      },
      "installation": {
        "title": "Installation Steps",
        "tip": "Tip",
        "note": "Note",
        "step1": {
          "title": "Clone Source Code",
          "description": "Clone GPT-Load source code repository from GitHub:",
          "tip": "If you need a specific version, use git checkout v1.x.x to switch to the corresponding version tag"
        },
        "step2": {
          "title": "Install Dependencies",
          "description": "Download and install Go module dependencies:",
          "code": "go mod tidy",
          "warning": "Ensure network connection is stable, some dependencies may need to be downloaded from overseas servers"
        },
        "step3": {
          "title": "Database Configuration",
          "config": {
            "title": "Create Configuration File",
            "code": "cp .env.example .env",
            "description": "Copy example configuration file and modify according to your environment"
          },
          "database": {
            "title": "Database Connection Configuration",
            "sqlite": "SQLite (recommended for development)",
            "sqliteCode": "DATABASE_DSN=./data/gpt-load.db",
            "mysql": "MySQL",
            "mysqlCode": "DATABASE_DSN=root:123456@tcp(mysql:3306)/gpt-load?charset=utf8mb4&parseTime=True&loc=Local",
            "postgresql": "PostgreSQL",
            "postgresqlCode": "DATABASE_DSN=postgres://postgres:123456@postgres:5432/gpt-load?sslmode=disable"
          }
        },
        "step4": {
          "title": "Build and Run",
          "frontend": {
            "title": "Build Frontend",
            "code": "cd web && npm install && npm run build"
          },
          "backend": {
            "title": "Run Backend Development Service",
            "code": "go run main.go"
          },
          "dev": {
            "title": "Run Frontend Development Service",
            "code": "cd web && npm run dev"
          }
        }
      },
      "development": {
        "title": "Development Guide",
        "structure": {
          "title": "Project Structure",
          "root": "gpt-load/",
          "internal": "internal/ # Internal business logic",
          "app": "app/ # Application initialization",
          "channel": "channel/ # Channel type management",
          "config": "config/ # Configuration management",
          "container": "container/ # Dig container service management",
          "db": "db/ # DB initialization and migration scripts",
          "errors": "errors/ # Error messages",
          "handler": "handler/ # Management API interfaces",
          "httpclient": "httpclient/ # HTTP client wrapper",
          "keypool": "keypool/ # Key pool management",
          "middleware": "middleware/ # Middleware",
          "models": "models/ # Data models",
          "proxy": "proxy/ # Proxy service",
          "response": "response/ # Response wrapper",
          "router": "router/ # Routing",
          "services": "services/ # Business logic layer",
          "store": "store/ # Unified memory",
          "syncer": "syncer/ # Cluster synchronizer",
          "types": "types/ # Type definitions",
          "utils": "utils/ # Utility functions",
          "version": "version/ # Version constants",
          "web": "web/ # Frontend resources",
          "gomod": "go.mod # Go module definition",
          "envexample": ".env.example # Configuration example",
          "dockercompose": "docker-compose.yml # Configuration example",
          "dockerfile": "Dockerfile # Configuration example",
          "makefile": "Makefile # Build rules",
          "maingo": "main.go # Entry program"
        }
      },
      "troubleshooting": {
        "title": "Troubleshooting",
        "error": "Error message",
        "solution": "Solution",
        "common": {
          "title": "Common Issues",
          "goVersion": {
            "title": "Go version too low",
            "error": "go version go1.xx.x: minimum supported version is go1.23",
            "solution": "Upgrade Go version to 1.23 or higher"
          },
          "dependency": {
            "title": "Dependency download failed",
            "cause": "Possible causes: network connection issues or proxy settings",
            "codeComment": "# Set Go proxy",
            "code": "go env -w GOPROXY=https://goproxy.cn,direct"
          }
        }
      },
      "nextSteps": {
        "title": "Next Steps",
        "description": "After source code deployment is complete, you can:",
        "customize": "Deeply understand code structure and customize features",
        "contribute": "Participate in open source projects and submit Pull Requests",
        "docker": "Build custom Docker images",
        "cicd": "Integrate into CI/CD pipelines",
        "configurationGuide": "Configuration Guide",
        "systemArchitecture": "System Architecture"
      }
    }
  },
  "integrations": {
    "title": "Integration Guide",
    "description": "GPT-Load supports integration with various AI applications and development tools. Through a unified proxy interface, you can easily integrate multiple AI services into your favorite applications, achieving load balancing and failover.",
    "advantages": {
      "title": "Integration Advantages",
      "items": [
        {
          "title": "Unified Interface",
          "description": "One configuration supports multiple AI services"
        },
        {
          "title": "Load Balancing",
          "description": "Automatically distribute requests to improve availability"
        },
        {
          "title": "Failover",
          "description": "Automatically switch to backup when service is abnormal"
        }
      ]
    },
    "integrations": [
      {
        "name": "Roo Code",
        "description": "Intelligent code assistant supporting multiple AI models",
        "status": "available",
        "icon": "Code2",
        "href": "/docs/integrations/roo-code",
        "category": "Development Tools"
      },
      {
        "name": "New API",
        "description": "Modern API development platform supporting multiple AI models",
        "status": "available",
        "icon": "Globe",
        "href": "/docs/integrations/new-api",
        "category": "API Tools"
      },
      {
        "name": "Cherry Studio",
        "description": "Desktop AI chat application supporting multiple AI models",
        "status": "available",
        "icon": "Sparkles",
        "href": "/docs/integrations/cherry-studio",
        "category": "Desktop Applications"
      },
      {
        "name": "Claude Code Router",
        "description": "Intelligent code routing tool supporting multi-model switching",
        "status": "available",
        "icon": "Terminal",
        "href": "/docs/integrations/claude-code-router",
        "category": "Development Tools"
      }
    ],
    "categories": [
      {
        "title": "Development Tools",
        "description": "Integration with various development tools and IDEs",
        "items": []
      },
      {
        "title": "API Tools",
        "description": "Integration with API development and testing platforms",
        "items": []
      },
      {
        "title": "Desktop Applications",
        "description": "Access configuration for desktop AI applications",
        "items": []
      }
    ],
    "status": {
      "available": "Available",
      "comingSoon": "Coming Soon"
    },
    "viewGuide": "View Integration Guide",
    "comingSoon": "Coming Soon",
    "contribution": {
      "title": "Contribute Integration Guide",
      "description": "If you have successfully integrated GPT-Load into other applications, welcome to contribute your integration guide. This will help more users benefit.",
      "githubLink": "Contribute on GitHub"
    }
  },
  "claudeCodeRouter": {
    "title": "Claude Code Router Integration Guide",
    "description": "This guide will help you integrate GPT-Load proxy service with Claude Code Router tool, enabling multi-model intelligent routing and code assistance features.",
    "prerequisites": {
      "title": "Prerequisites",
      "items": [
        "Ensure you have successfully deployed and started the GPT-Load service, running on http://localhost:3001 by default",
        "Node.js and npm environment installed"
      ]
    },
    "installation": {
      "title": "Tool Installation",
      "globalInstall": {
        "title": "Global Installation of Required Components"
      },
      "claudeCode": {
        "title": "Install Claude Code",
        "command": "npm install -g @anthropic-ai/claude-code"
      },
      "claudeCodeRouter": {
        "title": "Install Claude Code Router",
        "command": "npm install -g @musistudio/claude-code-router"
      },
      "reference": {
        "title": "Reference Documentation:",
        "url": "https://github.com/musistudio/claude-code-router/blob/main/README_zh.md",
        "text": "Claude Code Router Official Documentation"
      }
    },
    "configuration": {
      "title": "Configuration File Setup",
      "createConfig": {
        "title": "Create Configuration File"
      },
      "configPath": {
        "title": "Configuration File Path",
        "path": "~/.claude-code-router/config.json",
        "note": "If the directory doesn't exist, please create the directory structure first"
      },
      "configExample": {
        "title": "Configuration Example",
        "content": "{\n  \"Providers\": [\n    {\n      \"name\": \"gpt-load-openai\",\n      \"api_base_url\": \"http://localhost:3001/proxy/openai/v1/chat/completions\",\n      \"api_key\": \"sk-123456\",\n      \"models\": [\n        \"gpt-4.1-mini\",\n        \"gpt-4.1-nano\"\n      ]\n    },\n    {\n      \"name\": \"gpt-load-gemini\",\n      \"api_base_url\": \"http://localhost:3001/proxy/gemini/v1beta/models/\",\n      \"api_key\": \"sk-123456\",\n      \"models\": [\n        \"gemini-2.5-pro\",\n        \"gemini-2.5-flash\"\n      ],\n      \"transformer\": {\n        \"use\": [\n          \"gemini\"\n        ]\n      }\n    },\n    {\n      \"name\": \"gpt-load-gemini-openai\",\n      \"api_base_url\": \"http://localhost:3001/proxy/gemini/v1beta/openai/chat/completions\",\n      \"api_key\": \"sk-123456\",\n      \"models\": [\n        \"gemini-2.5-pro\",\n        \"gemini-2.5-flash\"\n      ]\n    },\n    {\n      \"name\": \"gpt-load-anthropic\",\n      \"api_base_url\": \"http://localhost:3001/proxy/anthropic/v1/messages\",\n      \"api_key\": \"sk-123456\",\n      \"models\": [\n        \"claude-sonnet-4-20250514\",\n        \"claude-3-haiku-20240307\"\n      ],\n      \"transformer\": {\n        \"use\": [\n          \"Anthropic\"\n        ]\n      }\n    }\n  ],\n  \"Router\": {\n    \"default\": \"gpt-load-gemini,gemini-2.5-pro\",\n    \"background\": \"gpt-load-gemini,gemini-2.5-flash\",\n    \"think\": \"gpt-load-gemini,gemini-2.5-pro\",\n    \"longContext\": \"gpt-load-gemini,gemini-2.5-pro\",\n    \"longContextThreshold\": 60000,\n    \"webSearch\": \"gpt-load-gemini,gemini-2.5-flash\"\n  }\n}"
      }
    },
    "explanation": {
      "title": "Configuration Explanation",
      "providers": {
        "title": "Providers Configuration Details",
        "items": [
          {
            "name": "gpt-load-openai",
            "description": "OpenAI Channel Type",
            "type": "green"
          },
          {
            "name": "gpt-load-gemini",
            "description": "Gemini Native Format",
            "type": "blue"
          },
          {
            "name": "gpt-load-gemini-openai",
            "description": "Gemini OpenAI Compatible Format",
            "type": "cyan"
          },
          {
            "name": "gpt-load-anthropic",
            "description": "Anthropic Claude Channel",
            "type": "purple"
          }
        ],
        "important": {
          "title": "Important Configuration Notes",
          "items": [
            "Replace localhost:3001 with your actual GPT-Load access address",
            "Adjust providers in Providers section according to your actual channel types configured in GPT-Load",
            "Path components like openai, gemini are the group names you configured in GPT-Load",
            "Model list should be adjusted according to the models actually supported by your channels",
            "In Anthropic configuration, transformer.use value should be Anthropic (capitalized)"
          ]
        }
      },
      "router": {
        "title": "Router Configuration",
        "items": [
          {
            "key": "default",
            "description": "Default Model"
          },
          {
            "key": "background",
            "description": "Background Tasks"
          },
          {
            "key": "think",
            "description": "Think Mode"
          },
          {
            "key": "longContext",
            "description": "Long Context"
          },
          {
            "key": "webSearch",
            "description": "Web Search"
          }
        ],
        "note": {
          "title": "Example Configuration Note:",
          "description": "The above example mainly configures Gemini models. You can configure other model combinations as needed, such as OpenAI or Anthropic models."
        }
      }
    },
    "usage": {
      "title": "Launch and Usage",
      "launch": {
        "title": "Launch Command",
        "commandTitle": "Start Claude Code Router",
        "command": "ccr code",
        "description": "After configuration is complete, use this command to start the Claude Code Router tool"
      }
    },
    "verification": {
      "title": "Verify Configuration",
      "test": {
        "title": "Test Connection",
        "description": "After successful startup, try executing some basic code-related tasks to confirm that all models can respond normally. If you encounter issues, please check GPT-Load service status, configuration file syntax, and network connection."
      }
    },
    "relatedResources": {
      "title": "Related Resources",
      "officialDocs": {
        "url": "https://github.com/musistudio/claude-code-router/blob/main/README_zh.md",
        "text": "Claude Code Router Official Documentation"
      },
      "gptLoadConfig": "GPT-Load Configuration Guide",
      "channelTypes": "Channel Types Guide"
    }
  },
  "newApi": {
    "title": "New API Integration Guide",
    "description": "This guide will help you integrate GPT-Load proxy service with New API platform, supporting OpenAI, Gemini, Gemini OpenAI compatible, and Anthropic channel types.",
    "prerequisites": {
      "title": "Prerequisites",
      "description": "Ensure you have successfully deployed and started the GPT-Load service, running on http://localhost:3001 by default"
    },
    "openai": {
      "title": "OpenAI Channel Configuration",
      "imageAlt": "New API OpenAI Configuration Screenshot",
      "configSteps": {
        "title": "Configuration Steps",
        "selectType": {
          "title": "Select Type",
          "description": "Select \"OpenAI\" type in New API"
        },
        "configKey": {
          "title": "Configure Key",
          "example": "sk-123456",
          "note": "Use the proxy key you configured in GPT-Load"
        },
        "apiAddress": {
          "title": "Set API Address",
          "example": "http://localhost:3001/proxy/openai",
          "note": "Where \"openai\" is the group name you configured in GPT-Load"
        },
        "addModel": {
          "title": "Add Models and Test",
          "description": "Add model list and perform testing verification"
        }
      }
    },
    "gemini": {
      "title": "Gemini Channel Configuration",
      "imageAlt": "New API Gemini Configuration Screenshot",
      "configSteps": {
        "title": "Configuration Steps",
        "selectType": {
          "title": "Select Type",
          "description": "Select \"Google Gemini\" type in New API"
        },
        "configKey": {
          "title": "Configure Key",
          "example": "sk-123456",
          "note": "Use the proxy key you configured in GPT-Load"
        },
        "apiAddress": {
          "title": "Set API Address",
          "example": "http://localhost:3001/proxy/gemini",
          "note": "Where \"gemini\" is the group name you configured in GPT-Load"
        },
        "modelList": {
          "title": "Model List Configuration",
          "description": "Due to a bug in New API's Gemini type model list retrieval, manual model name entry is recommended when creating new channels"
        }
      },
      "modelListNotice": {
        "title": "Model List Retrieval Notice",
        "description": "New API's Gemini type may not automatically retrieve model lists when creating new channels. It's recommended to manually enter model names first. After creation, model lists can usually be retrieved normally in edit mode."
      }
    },
    "geminiThinking": {
      "title": "Gemini Thinking Configuration",
      "imageAlt": "New API Gemini Thinking Configuration Screenshot",
      "config": {
        "title": "Thinking Feature Setup",
        "enableAdaptation": {
          "title": "Enable Thinking Adaptation",
          "description": "In New API's System Settings ‚Üí Model Related Settings, select \"Enable Gemini Thinking Suffix Adaptation\""
        },
        "useSuffix": {
          "title": "Use Thinking Suffix",
          "enableSuffix": "-thinking",
          "enableDescription": "Enable thinking mode",
          "disableSuffix": "-nothinking",
          "disableDescription": "Disable thinking mode",
          "note": "Note: gemini-2.5-pro model cannot disable thinking functionality"
        }
      },
      "warning": {
        "title": "Important Warning",
        "description": "After configuring thinking functionality in New API, do not configure thinking-related parameters again in GPT-Load's parameter override to avoid conflicts from duplicate configuration."
      }
    },
    "geminiSearch": {
      "title": "Gemini Search Feature Configuration",
      "config": {
        "title": "Enable Official Search Tools",
        "configChoice": {
          "title": "Configuration Choice",
          "description": "Search models can be configured in either New API or GPT-Load (only configure in one place)"
        },
        "parameterConfig": {
          "title": "Parameter Configuration",
          "description": "Add the following configuration to parameter override:",
          "example": "{\n  \"tools\": [\n    {\n      \"google_search\": {}\n    }\n  ]\n}",
          "note": "After configuration, the official search tool functionality will be enabled"
        }
      }
    },
    "geminiOpenAI": {
      "title": "Gemini OpenAI Compatible Format",
      "imageAlt": "New API Gemini OpenAI Compatible Format Configuration Screenshot",
      "configSteps": {
        "title": "Configuration Steps",
        "selectType": {
          "title": "Select Type",
          "description": "Select \"Custom Channel\" type in New API"
        },
        "configKey": {
          "title": "Configure Key",
          "example": "sk-123456",
          "note": "Use the proxy key you configured in GPT-Load"
        },
        "fullAddress": {
          "title": "Set Full Address",
          "example": "http://localhost:3001/proxy/gemini/v1beta/openai/chat/completions",
          "note": "Where \"gemini\" is the group name you configured in GPT-Load"
        },
        "manualModel": {
          "title": "Manually Add Models",
          "description": "Compatible format cannot automatically retrieve model lists, manual model name entry is required"
        }
      },
      "limitation": {
        "title": "Compatible Mode Limitations",
        "description": "When using OpenAI compatible mode, thinking and search parameters cannot be configured. For these advanced features, use native Gemini type instead."
      }
    },
    "anthropic": {
      "title": "Anthropic (Claude) Channel Configuration",
      "imageAlt": "New API Anthropic Configuration Screenshot",
      "configSteps": {
        "title": "Configuration Steps",
        "selectType": {
          "title": "Select Type",
          "description": "Select \"Anthropic Claude\" type in New API"
        },
        "configKey": {
          "title": "Configure Key",
          "example": "sk-123456",
          "note": "Use the proxy key you configured in GPT-Load"
        },
        "apiAddress": {
          "title": "Set API Address",
          "example": "http://localhost:3001/proxy/anthropic",
          "note": "Where \"anthropic\" is the group name you configured in GPT-Load"
        }
      }
    },
    "importantNotes": {
      "title": "Important Notes",
      "configuration": {
        "title": "Configuration Notes",
        "items": [
          "Replace the GPT-Load access address in examples with your actual service address",
          "Group names in paths (like openai, gemini, anthropic) must match your actual configuration in GPT-Load",
          "Test configuration in a small scope first, then use officially after confirmation"
        ]
      }
    },
    "relatedResources": {
      "title": "Related Resources",
      "newApiDocs": {
        "url": "https://www.newapi.ai/getting-started/",
        "text": "New API Official Documentation"
      },
      "gptLoadConfig": "GPT-Load Configuration Guide",
      "channelTypes": "Channel Types Guide"
    }
  },
  "cherryStudio": {
    "title": "Cherry Studio Integration Guide",
    "description": "This guide will help you integrate GPT-Load proxy service with Cherry Studio AI client, supporting complete configuration for OpenAI, Gemini, Gemini OpenAI compatible, and Anthropic channel types.",
    "prerequisites": {
      "title": "Prerequisites",
      "description": "Ensure you have successfully deployed and started the GPT-Load service, running on http://localhost:3001 by default"
    },
    "generalSteps": {
      "title": "General Setup Steps",
      "serviceLocation": {
        "title": "Service Setup Location",
        "step1": {
          "title": "Access Settings Page",
          "description": "Click \"Settings\" ‚Üí \"Model Services\" in the bottom left corner of Cherry Studio"
        },
        "step2": {
          "title": "Add New Service",
          "description": "Click the \"Add\" button at the bottom of the page (do not use existing services from the list)"
        },
        "step3": {
          "title": "Get Models After Configuration",
          "description": "Click the \"Manage\" button to get the model list and select the desired models"
        }
      },
      "reminder": {
        "title": "Important Reminder",
        "description": "All channel types follow the same setup process: Select provider type ‚Üí Configure API address and key ‚Üí Get model list. Only the provider type and API address configuration differ."
      }
    },
    "openai": {
      "title": "OpenAI Channel Configuration",
      "create": {
        "title": "Step 1: Create Service",
        "stepsTitle": "Creation Steps",
        "step1": {
          "title": "Enter Service Name",
          "description": "Set an easily recognizable name for your service"
        },
        "step2": {
          "title": "Select Provider Type",
          "description": "Select OpenAI from the provider type dropdown"
        },
        "imageAlt": "Cherry Studio OpenAI service creation screenshot"
      },
      "config": {
        "title": "Step 2: Configure Service",
        "parametersTitle": "Configuration Parameters",
        "apiKey": {
          "title": "Configure API Key",
          "description": "Use the proxy key configured in your GPT-Load"
        },
        "apiUrl": {
          "title": "Set API Address",
          "description": "Where \"openai\" is the group name configured in your GPT-Load"
        },
        "models": {
          "title": "Get Model List",
          "description": "After configuration, click the \"Manage\" button to get and select the required models"
        },
        "imageAlt": "Cherry Studio OpenAI service configuration screenshot"
      }
    },
    "gemini": {
      "title": "Gemini Channel Configuration",
      "create": {
        "title": "Step 1: Create Service",
        "stepsTitle": "Creation Steps",
        "step1": {
          "title": "Enter Service Name",
          "description": "Set an easily recognizable name for your Gemini service"
        },
        "step2": {
          "title": "Select Provider Type",
          "description": "Select Gemini from the provider type dropdown"
        },
        "imageAlt": "Cherry Studio Gemini service creation screenshot"
      },
      "config": {
        "title": "Step 2: Configure Service",
        "parametersTitle": "Configuration Parameters",
        "apiKey": {
          "title": "Configure API Key",
          "description": "Use the proxy key configured in your GPT-Load"
        },
        "apiUrl": {
          "title": "Set API Address",
          "description": "Where \"gemini\" is the group name configured in your GPT-Load"
        },
        "models": {
          "title": "Get Model List",
          "description": "After configuration, click the \"Manage\" button to get and select the required models"
        },
        "imageAlt": "Cherry Studio Gemini service configuration screenshot"
      }
    },
    "geminiOpenai": {
      "title": "Gemini OpenAI Compatible Format",
      "create": {
        "title": "Step 1: Create Service",
        "subtitle": "Using Gemini channel's OpenAI compatible interface format",
        "stepsTitle": "Creation Steps",
        "step1": {
          "title": "Enter Service Name",
          "description": "Set a name for your Gemini OpenAI compatible service"
        },
        "step2": {
          "title": "Select Provider Type",
          "description": "Use OpenAI type to support compatible interface"
        },
        "imageAlt": "Cherry Studio Gemini OpenAI compatible service creation screenshot"
      },
      "config": {
        "title": "Step 2: Configure Service",
        "parametersTitle": "Configuration Parameters",
        "apiKey": {
          "title": "Configure API Key",
          "description": "Use the proxy key configured in your GPT-Load"
        },
        "apiUrl": {
          "title": "Set API Address",
          "description": "Note: The address must end with \"/\" to prevent Cherry Studio from automatically adding v1 path"
        },
        "models": {
          "title": "Get Model List",
          "description": "After configuration, click the \"Manage\" button to get and select the required models"
        },
        "imageAlt": "Cherry Studio Gemini OpenAI compatible service configuration screenshot"
      },
      "warning": {
        "title": "Critical Configuration Note",
        "description": "The API address must end with \"/\"! This is a Cherry Studio rule requirement to ensure v1 path is not automatically added, guaranteeing the compatible interface works properly."
      }
    },
    "anthropic": {
      "title": "Anthropic (Claude) Channel Configuration",
      "create": {
        "title": "Step 1: Create Service",
        "stepsTitle": "Creation Steps",
        "step1": {
          "title": "Enter Service Name",
          "description": "Set an easily recognizable name for your Anthropic service"
        },
        "step2": {
          "title": "Select Provider Type",
          "description": "Select Anthropic from the provider type dropdown"
        },
        "imageAlt": "Cherry Studio Anthropic service creation screenshot"
      },
      "config": {
        "title": "Step 2: Configure Service",
        "parametersTitle": "Configuration Parameters",
        "apiKey": {
          "title": "Configure API Key",
          "description": "Use the proxy key configured in your GPT-Load"
        },
        "apiUrl": {
          "title": "Set API Address",
          "description": "Where \"anthropic\" is the group name configured in your GPT-Load"
        },
        "models": {
          "title": "Get Model List",
          "description": "After configuration, click the \"Manage\" button to get and select the required models"
        },
        "imageAlt": "Cherry Studio Anthropic service configuration screenshot"
      }
    },
    "importantNotes": {
      "title": "Important Notes",
      "configurationNotes": {
        "title": "Configuration Considerations",
        "items": [
          "Please replace the GPT-Load access address in the examples with your actual service address",
          "The group names in the path (such as openai, gemini, anthropic) need to match your actual configuration in GPT-Load",
          "Use your actual proxy key configured in GPT-Load, do not use the example sk-123456",
          "After configuration, remember to select the newly added model in the chat interface for testing"
        ]
      }
    },
    "relatedResources": {
      "title": "Related Resources",
      "cherryStudioDocs": "Cherry Studio Official Documentation",
      "gptLoadConfig": "GPT-Load Configuration Guide",
      "channelTypes": "Channel Types Documentation"
    }
  },
  "introduction": {
    "title": "GPT-Load Project Introduction",
    "subtitle": "A high-performance, enterprise-grade AI interface transparent proxy service, specifically designed for enterprises and developers who need to integrate multiple AI services. Built with Go language, featuring intelligent key management, load balancing, and comprehensive monitoring capabilities, designed for high-concurrency production environments.",
    "coreConcept": {
      "title": "Core Concept",
      "transparentProxy": {
        "title": "Transparent Proxy",
        "description": "GPT-Load serves as a transparent proxy service, completely preserving the native API formats of various AI service providers without any format conversion or unification. How users request GPT-Load is exactly how GPT-Load requests upstream services, achieving completely transparent proxy functionality."
      }
    },
    "supportedServices": {
      "title": "Supported AI Services",
      "openai": {
        "features": [
          "‚Ä¢ Official OpenAI API",
          "‚Ä¢ Azure OpenAI",
          "‚Ä¢ All third-party services compatible with OpenAI format"
        ]
      },
      "gemini": {
        "features": [
          "‚Ä¢ Gemini Pro",
          "‚Ä¢ Gemini Pro Vision",
          "‚Ä¢ Support for multimodal features"
        ]
      },
      "claude": {
        "features": [
          "‚Ä¢ Claude series models",
          "‚Ä¢ High-quality conversation generation",
          "‚Ä¢ Native API format support"
        ]
      }
    },
    "coreFeatures": {
      "title": "Core Features",
      "highPerformance": {
        "title": "High-Performance Architecture",
        "description": "Zero-copy streaming transmission, Go goroutine-based concurrency model, supporting high-concurrency connections"
      },
      "keyManagement": {
        "title": "Intelligent Key Management",
        "description": "Group management, dynamic rotation, automatic retry, ensuring high service availability"
      },
      "loadBalancing": {
        "title": "Load Balancing",
        "description": "Multi-upstream support, weight configuration, health checks, intelligent routing to available nodes"
      },
      "clusterSupport": {
        "title": "Cluster Support",
        "description": "Master/Slave architecture, stateless design, supporting horizontal scaling"
      },
      "hotReload": {
        "title": "Hot Reload Configuration",
        "description": "Three-tier configuration system: environment variables, system settings, group configuration, supporting hot updates"
      },
      "adminPanel": {
        "title": "Admin Panel",
        "description": "Vue 3 modern interface, real-time monitoring, log viewing, configuration management"
      }
    },
    "techStack": {
      "title": "Technology Stack",
      "backend": {
        "title": "Backend Technologies",
        "items": [
          {"name": "Go 1.23+", "desc": "Primary programming language"},
          {"name": "Gin", "desc": "HTTP Web framework"},
          {"name": "GORM", "desc": "ORM database operation framework"},
          {"name": "MySQL 8.2+", "desc": "Primary database storage"},
          {"name": "Redis", "desc": "Distributed cache and state management"},
          {"name": "Uber Dig", "desc": "Dependency injection container"}
        ]
      },
      "frontend": {
        "title": "Frontend & DevOps",
        "items": [
          {"name": "Vue 3", "desc": "Frontend framework"},
          {"name": "TypeScript", "desc": "Type safety"},
          {"name": "Naive UI", "desc": "UI component library"},
          {"name": "Docker", "desc": "Containerized deployment"},
          {"name": "Docker Compose", "desc": "Container orchestration"},
          {"name": "GitHub Actions", "desc": "CI/CD pipeline"}
        ]
      }
    },
    "architectureAdvantages": {
      "title": "Architecture Advantages",
      "microservices": {
        "title": "Microservices Architecture",
        "items": [
          "‚Ä¢ Modular design",
          "‚Ä¢ Dependency injection",
          "‚Ä¢ Interface-driven"
        ]
      },
      "distributed": {
        "title": "Distributed Design",
        "items": [
          "‚Ä¢ Master/Slave mode",
          "‚Ä¢ Distributed locks",
          "‚Ä¢ Cache synchronization"
        ]
      },
      "highAvailability": {
        "title": "High Availability",
        "items": [
          "‚Ä¢ Graceful degradation",
          "‚Ä¢ Fault recovery",
          "‚Ä¢ Resource protection"
        ]
      }
    },
    "useCases": {
      "title": "Use Cases",
      "enterprise": {
        "title": "Enterprise AI Services",
        "items": [
          "‚Ä¢ Large-scale API calls",
          "‚Ä¢ Cost control optimization",
          "‚Ä¢ Service stability assurance"
        ]
      },
      "developer": {
        "title": "Developer Tools",
        "items": [
          "‚Ä¢ Unified API access",
          "‚Ä¢ Debugging and monitoring",
          "‚Ä¢ Rapid deployment"
        ]
      },
      "multiTenant": {
        "title": "Multi-tenant Services",
        "items": [
          "‚Ä¢ Tenant isolation",
          "‚Ä¢ Configuration customization",
          "‚Ä¢ Usage statistics"
        ]
      }
    },
    "deepDive": {
      "title": "Deep Dive into GPT-Load",
      "subtitle": "Explore GPT-Load's core technical architecture and high-performance design philosophy, learn how to achieve ultimate proxy performance",
      "performance": {
        "title": "Performance Details",
        "subtitle": "Understanding ultimate performance design",
        "features": [
          "Zero I/O operation proxy mechanism",
          "Zero-copy streaming transmission technology",
          "Lock-free concurrent processing architecture",
          "Ultra-low resource usage optimization"
        ]
      },
      "architecture": {
        "title": "Architecture Design",
        "subtitle": "Deep dive into system design philosophy",
        "features": [
          "Intelligent key management mechanism",
          "Path processing strategy design",
          "Distributed cluster architecture",
          "High availability guarantee mechanism"
        ]
      }
    },
    "gettingStarted": {
      "title": "Getting Started with GPT-Load",
      "description": "Deploy quickly with Docker Compose, start a complete AI interface proxy service in just a few minutes",
      "button": "View Deployment Guide"
    }
  },
  "rooCode": {
    "title": "Roo Code Integration Guide",
    "description": "This guide will help you integrate GPT-Load proxy service into Roo Code intelligent code assistant, supporting OpenAI, Gemini, and Anthropic channel types.",
    "prerequisites": {
      "title": "Prerequisites",
      "description": "Ensure you have successfully deployed and started the GPT-Load service, running by default at http://localhost:3001"
    },
    "openai": {
      "title": "OpenAI Channel Configuration",
      "imageAlt": "OpenAI Compatible provider configuration screenshot",
      "steps": {
        "title": "Configuration Steps",
        "selectProvider": {
          "title": "Select Provider",
          "description": "Select \"OpenAI Compatible\" provider in Roo Code"
        },
        "setProxy": {
          "title": "Set Proxy Address",
          "url": "http://localhost:3001/proxy/openai/v1",
          "note": "Where \"openai\" is the group name you configured in GPT-Load"
        },
        "configKey": {
          "title": "Configure API Key",
          "description": "Enter the proxy key configured in GPT-Load"
        }
      }
    },
    "gemini": {
      "title": "Gemini Channel Configuration",
      "method1": {
        "title": "Method 1: Google Gemini Provider",
        "subtitle": "Using native Gemini interface format (recommended)",
        "imageAlt": "Google Gemini provider configuration screenshot",
        "steps": {
          "title": "Configuration Steps",
          "selectProvider": {
            "title": "Select Provider",
            "description": "Select \"Google Gemini\" provider in Roo Code"
          },
          "enableCustomUrl": {
            "title": "Enable Custom Base URL",
            "description": "Check \"Use custom base URL\" option"
          },
          "setProxy": {
            "title": "Set Proxy Address",
            "url": "http://localhost:3001/proxy/gemini",
            "note": "Where \"gemini\" is the group name you configured in GPT-Load"
          },
          "configKey": {
            "title": "Configure API Key",
            "description": "Enter your Gemini API Key"
          }
        }
      },
      "method2": {
        "title": "Method 2: OpenAI Compatible Format",
        "subtitle": "Using OpenAI compatible interface format",
        "imageAlt": "Gemini OpenAI Compatible provider configuration screenshot",
        "steps": {
          "title": "Configuration Steps",
          "selectProvider": {
            "title": "Select Provider",
            "description": "Select \"OpenAI Compatible\" provider in Roo Code"
          },
          "setProxy": {
            "title": "Set Proxy Address",
            "url": "http://localhost:3001/proxy/gemini/v1beta/openai",
            "note": "Where \"gemini\" is the group name you configured in GPT-Load"
          },
          "configKey": {
            "title": "Configure API Key",
            "description": "Enter your Gemini API Key"
          }
        }
      },
      "recommendation": {
        "title": "Configuration Recommendation",
        "description": "We recommend using Method 1: Google Gemini Provider, as it uses the native Gemini interface format, providing better compatibility and complete feature support."
      }
    },
    "anthropic": {
      "title": "Anthropic (Claude) Channel Configuration",
      "imageAlt": "Anthropic provider configuration screenshot",
      "steps": {
        "title": "Configuration Steps",
        "selectProvider": {
          "title": "Select Provider",
          "description": "Select \"Anthropic\" provider in Roo Code"
        },
        "setProxy": {
          "title": "Set Proxy Address",
          "url": "http://localhost:3001/proxy/anthropic",
          "note": "Where \"anthropic\" is the group name you configured in GPT-Load"
        },
        "configKey": {
          "title": "Configure API Key",
          "description": "Enter your Anthropic API Key"
        }
      }
    },
    "verification": {
      "title": "Verify Configuration",
      "test": {
        "title": "Test Connection",
        "description": "After configuration is complete, send a test message in Roo Code to confirm normal response. If you encounter issues, please check if the GPT-Load service is running normally and if the group name is correct."
      }
    },
    "relatedResources": {
      "title": "Related Resources",
      "rooCodeDocs": "Roo Code Official Documentation",
      "gptLoadConfig": "GPT-Load Configuration Guide",
      "channelTypes": "Channel Types Documentation"
    }
  },
  "sponsor": {
    "title": "Sponsor",
    "subtitle": "If GPT-Load helps you, welcome to buy the author a coffee ‚òïÔ∏è",
    "paymentMethods": {
      "wechat": {
        "title": "WeChat",
        "description": "Scan QR code to sponsor",
        "qrCodeAlt": "WeChat payment QR code",
        "instruction": "WeChat scan"
      },
      "alipay": {
        "title": "Alipay",
        "description": "Scan QR code to sponsor",
        "qrCodeAlt": "Alipay payment QR code",
        "instruction": "Alipay scan"
      }
    },
    "onlinePlatform": {
      "title": "Online Sponsor Platform",
      "afdian": {
        "title": "Afdian Sponsor",
        "description": "Through Afdian platform, you can choose one-time sponsorship or regular support for project development"
      }
    },
    "thankYou": {
      "title": "Thank You for Your Support",
      "message": "Every support from you is our motivation to continuously improve GPT-Load. We deeply appreciate it regardless of the amount!",
      "tags": [
        "üíù Every heart counts",
        "üöÄ Make the project better",
        "‚ù§Ô∏è Long live open source"
      ]
    },
    "alternativeSupport": {
      "title": "Other Support Methods",
      "github": {
        "title": "‚≠ê GitHub Star"
      },
      "issues": {
        "title": "üêõ Report Issues"
      },
      "contribute": {
        "title": "üîß Contribute Code"
      }
    }
  },
  "contributors": {
    "title": "Contributors",
    "description": "Thanks to all the developers who have contributed to the GPT-Load project!",
    "thanks": {
      "title": "Acknowledgments",
      "message": "GPT-Load's growth to this day is inseparable from the support of every contributor in the community. Whether it's code contributions, issue reports, documentation improvements, or feature suggestions, every contribution drives the project forward.",
      "note": "The project adopts an open-source collaborative model, and we welcome more developers to join us!"
    },
    "list": {
      "title": "Project Contributors",
      "loading": "Loading contributor information...",
      "error": "Loading failed, please try again later",
      "alt": "GPT-Load project contributors",
      "viewOnGithub": "View on GitHub"
    },
    "howTo": {
      "title": "How to Contribute",
      "codeTitle": "Code Contributions",
      "codeItems": [
        "Fork the repository",
        "Create feature branch",
        "Submit code changes",
        "Create Pull Request"
      ],
      "otherTitle": "Other Contributions",
      "otherItems": [
        "Report bugs and issues",
        "Improve documentation",
        "Provide feature suggestions",
        "Participate in community discussions"
      ]
    },
    "cta": {
      "github": "Visit GitHub",
      "issues": "Submit Issues"
    }
  }
}